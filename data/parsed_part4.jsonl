{"id": "9a6f493a05", "source_url": "https://documentation.ubuntu.com/server/how-to/samba/member-server-in-an-ad-domain/", "title": "Member server in an Active Directory domain - Ubuntu Server documentation", "text": "Member server in an Active Directory domain - Ubuntu Server documentation\nContents\nMenu\nExpand\nLight mode\nDark mode\nAuto light/dark, in light mode\nAuto light/dark, in dark mode\nSkip to content\nBack to top\nView this page\nMember server in an Active Directory domain\n¶\nA Samba server needs to join the Active Directory (AD) domain before it can serve files and printers to Active Directory users. This is different from\nNetwork User Authentication with SSSD\n, where we integrate the AD users and groups into the local Ubuntu system as if they were local.\nFor Samba to authenticate these users via Server Message Block (SMB) authentication protocols, we need both for the remote users to be “seen”, and for Samba itself to be aware of the domain. In this scenario, Samba is called a Member Server or Domain Member.\nSee also\nSamba itself has the necessary tooling to join an Active Directory domain. It requires a sequence of manual steps and configuration file editing, which is\nthoroughly documented on the Samba wiki\n. It’s useful to read that documentation to get an idea of the steps necessary, and the decisions you will need to make.\nUse\nrealmd\nto join the Active Directory domain\n¶\nFor this guide, though, we are going to use the\nrealmd\npackage and instruct it to use the Samba tooling for joining the AD domain. This package will make certain decisions for us which will work for most cases, but more complex setups involving multiple or very large domains might require additional tweaking.\nInstall\nrealmd\n¶\nFirst, let’s install the necessary packages:\nsudo\napt\ninstall\nrealmd\nsamba\nIn order to have the joined machine registered in the AD\nDNS\n, it needs to have an\nFQDN\nset. You might have that already, if running the\nhostname\n-f\ncommand returns a full\nhostname\nwith domain. If it doesn’t, then set the hostname as follows:\nsudo\nhostnamectl\nhostname\n<yourfqdn>\nFor this guide, we will be using\nj1.internal.example.fake\n, and the AD domain will be\ninternal.example.fake\n.\nVerify the AD server\n¶\nNext, we need to verify that the AD server is both reachable and known by running the following command:\nsudo\nrealm\ndiscover\ninternal.example.fake\nThis should provide an output like this, given our setup:\ninternal.example.fake\n  type: kerberos\n  realm-name: INTERNAL.EXAMPLE.FAKE\n  domain-name: internal.example.fake\n  configured: no\n  server-software: active-directory\n  client-software: sssd\n  required-package: sssd-tools\n  required-package: sssd\n  required-package: libnss-sss\n  required-package: libpam-sss\n  required-package: adcli\n  required-package: samba-common-bin\nrealm\nis suggesting a set of packages for the discovered domain, but we will override that and select the Samba tooling for this join, because we want Samba to become a Member Server.\nJoin the AD domain\n¶\nLet’s join the domain in verbose mode so we can see all the steps:\nsudo\nrealm\njoin\n-v\n--membership-software\n=\nsamba\n--client-software\n=\nwinbind\ninternal.example.fake\nThis should produce the following output for us:\n* Resolving: _ldap._tcp.internal.example.fake\n * Performing LDAP DSE lookup on: 10.0.16.5\n * Successfully discovered: internal.example.fake\nPassword for Administrator:\n * Unconditionally checking packages\n * Resolving required packages\n * Installing necessary packages: libnss-winbind samba-common-bin libpam-winbind winbind\n * LANG=C LOGNAME=root /usr/bin/net --configfile /var/cache/realmd/realmd-smb-conf.A53NO1 -U Administrator --use-kerberos=required ads join internal.example.fake\nPassword for [INTEXAMPLE\\Administrator]:\nUsing short domain name -- INTEXAMPLE\nJoined 'J1' to dns domain 'internal.example.fake'\n * LANG=C LOGNAME=root /usr/bin/net --configfile /var/cache/realmd/realmd-smb-conf.A53NO1 -U Administrator ads keytab create\nPassword for [INTEXAMPLE\\Administrator]:\n * /usr/sbin/update-rc.d winbind enable\n * /usr/sbin/service winbind restart\n * Successfully enrolled machine in realm\nNote\nThis command also installed the\nlibpam-winbind\npackage,\nwhich allows AD users to authenticate to other services on this system via PAM, like SSH or console logins\n. For example, if your SSH server allows password authentication (\nPasswordAuthentication\nyes\nin\n/etc/ssh/sshd_config\n), then the domain users will be allowed to login remotely on this system via SSH.\nIf you don’t expect or need AD users to log into this system (unless it’s via Samba or Windows), then it’s safe and probably best to remove the\nlibpam-winbind\npackage.\nUntil\nbug #1980246\nis fixed, one extra step is needed:\nConfigure\n/etc/nsswitch.conf\nby adding the word\nwinbind\nto the\npasswd\nand\ngroup\nlines as shown below:\npasswd:         files systemd winbind\ngroup:          files systemd winbind\nNow you will be able to query users from the AD domain. Winbind adds the short domain name as a prefix to domain users and groups:\n$ getent passwd INTEXAMPLE\\\\Administrator\nINTEXAMPLE\\administrator:*:2000500:2000513::/home/administrator@INTEXAMPLE:/bin/bash\nYou can find out the short domain name in the\nrealm\noutput shown earlier, or inspect the\nworkgroup\nparameter of\n/etc/samba/smb.conf\n.\nCommon installation options\n¶\nWhen domain users and groups are brought to the Linux world, a bit of translation needs to happen, and sometimes new values need to be created. For example, there is no concept of a “login shell” for AD users, but it exists in Linux.\nThe following are some common\n/etc/samba/smb.conf\noptions you are likely to want to tweak in your installation. The\nsmb.conf(5)\nmanual page explains the\n%\nvariable substitutions and other details:\nhome directory\ntemplate\nhomedir\n=\n/home/%U@%D\n(Another popular choice is\n/home/%D/%U\n)\nlogin shell\ntemplate\nshell\n=\n/bin/bash\nwinbind\nseparator\n=\n\\\nThis is the\n\\\ncharacter between the short domain name and the user or group name that we saw in the\ngetent\npasswd\noutput above.\nwinbind\nuse\ndefault\ndomain\nIf this is set to\nyes\n, then the domain name will not be part of the users and groups. Setting this to\nyes\nmakes the system more friendly towards Linux users, as they won’t have to remember to include the domain name every time a user or group is referenced. However, if multiple domains are involved, such as in an AD forest or other form of domain trust relationship, then leave this setting at\nno\n(default).\nTo have the home directory created automatically the first time a user logs in to the system, and if you haven’t removed\nlibpam-winbind\n, then enable the\npam_mkhomedir\nmodule via this command:\nsudo\npam-auth-update\n--enable\nmkhomedir\nNote that this won’t apply to logins via Samba: this only creates the home directory for system logins like those via\nssh\nor the console.\nExport shares\n¶\nShares can be exported as usual. Since this is now a Member Server, there is no need to deal with user and group management. All of this is integrated with the Active Directory server we joined.\nFor example, let’s create a simple\n[storage]\nshare. Add this to the\n/etc/samba/smb.conf\nfile:\n[storage]\n    path = /storage\n    comment = Storage share\n    writable = yes\n    guest ok = no\nThen create the\n/storage\ndirectory. Let’s also make it\n1777\nso all users can use it, and then ask samba to reload its configuration:\nsudo\nmkdir\n-m\n1777\n/storage\nsudo\nsmbcontrol\nsmbd\nreload-config\nWith this, users from the AD domain will be able to access this share. For example, if there is a user\nubuntu\nthe following command would access the share from another system, using the domain credentials:\n$ smbclient //j1.internal.example.fake/storage -U INTEXAMPLE\\\\ubuntu\nEnter INTEXAMPLE\\ubuntu's password:\nTry \"help\" to get a list of possible commands.\nsmb: \\>\nAnd\nsmbstatus\non the member server will show the connected user:\n$ sudo smbstatus\n\nSamba version 4.15.5-Ubuntu\nPID     Username     Group        Machine                                   Protocol Version  Encryption           Signing\n----------------------------------------------------------------------------------------------------------------------------------------\n3631    INTEXAMPLE\\ubuntu INTEXAMPLE\\domain users 10.0.16.1 (ipv4:10.0.16.1:39534)          SMB3_11           -                    partial(AES-128-CMAC)\n\nService      pid     Machine       Connected at                     Encryption   Signing\n---------------------------------------------------------------------------------------------\nstorage      3631    10.0.16.1     Wed Jun 29 17:42:54 2022 UTC     -            -\n\nNo locked files\nYou can also restrict access to the share as usual. Just keep in mind the syntax for the domain users. For example, to restrict access to the\n[storage]\nshare we just created to\nonly\nmembers of the\nLTS\nReleases\ndomain group, add the\nvalid\nusers\nparameter like below:\n[storage]\n    path = /storage\n    comment = Storage share\n    writable = yes\n    guest ok = no\n    valid users = \"@INTEXAMPLE\\ LTS Releases\"\nChoose an\nidmap\nbackend\n¶\nrealm\nmade some choices for us when we joined the domain. A very important one is the\nidmap\nbackend, and it might need changing for more complex setups.\nUser and group identifiers on the AD side are not directly usable as identifiers on the Linux site. A\nmapping\nneeds to be performed.\nWinbind supports several\nidmap\nbackends, and each one has its own manual page. The three main ones are:\nidmap_ad(8)\nidmap_autorid(8)\nidmap_rid(8)\nChoosing the correct backend for each deployment type needs careful planing. Upstream has some guidelines at\nChoosing an\nidmap\nbackend\n, and each man page has more details and recommendations.\nThe\nrealm\ntool selects (by default) the\nrid\nbackend. This backend uses an algorithm to calculate the Unix user and group IDs from the respective RID value on the AD side. You might need to review the\nidmap\nconfig\nsettings in\n/etc/samba/smb.conf\nand make sure they can accommodate the number of users and groups that exist in the domain, and that the range does not overlap with users from other sources.\nFor example, these settings:\nidmap config * : range = 10000-999999\nidmap config intexample : backend = rid\nidmap config intexample : range = 2000000-2999999\nidmap config * : backend = tdb\nWill reserve the\n2,000,000\nthrough\n2,999,999\nrange for user and group ID allocations on the Linux side for the\nintexample\ndomain. The default backend (\n*\n, which acts as a “globbing” catch-all rule) is used for the\nBUILTIN\nuser and groups, and other domains (if they exist). It’s important that these ranges do not overlap.\nThe\nAdministrator\nuser we inspected before with\ngetent\npasswd\ncan give us a glimpse of how these ranges are used (output format changed for clarity):\n$\nid\nINTEXAMPLE\n\\\\\nAdministrator\nuid\n=\n2000500\n(\nINTEXAMPLE\n\\a\ndministrator\n)\ngid\n=\n2000513\n(\nINTEXAMPLE\n\\d\nomain\nusers\n)\ngroups\n=\n2000513\n(\nINTEXAMPLE\n\\d\nomain\nusers\n)\n,\n2000500\n(\nINTEXAMPLE\n\\a\ndministrator\n)\n,\n2000572\n(\nINTEXAMPLE\n\\d\nenied\nrodc\npassword\nreplication\ngroup\n)\n,\n2000519\n(\nINTEXAMPLE\n\\e\nnterprise\nadmins\n)\n,\n2000518\n(\nINTEXAMPLE\n\\s\nchema\nadmins\n)\n,\n2000520\n(\nINTEXAMPLE\n\\g\nroup\npolicy\ncreator\nowners\n)\n,\n2000512\n(\nINTEXAMPLE\n\\d\nomain\nadmins\n)\n,\n10001\n(\nBUILTIN\n\\u\nsers\n)\n,\n10000\n(\nBUILTIN\n\\a\ndministrators\n)\nFurther reading\n¶\nThe Samba Wiki", "meta": {"site": "documentation.ubuntu.com", "crawl_ts": "2025-11-27T10:38:27Z", "original_len_words": 1679}}
{"id": "5f2d29032a", "source_url": "https://documentation.ubuntu.com/server/how-to/samba/mount-cifs-shares-permanently/", "title": "How to mount CIFS shares permanently - Ubuntu Server documentation", "text": "How to mount CIFS shares permanently - Ubuntu Server documentation\nContents\nMenu\nExpand\nLight mode\nDark mode\nAuto light/dark, in light mode\nAuto light/dark, in dark mode\nSkip to content\nBack to top\nView this page\nHow to mount CIFS shares permanently\n¶\nCommon Internet File System (CIFS) shares are a file-sharing protocol used (mainly) in Windows for accessing files and resources (such as printers) over a network.\nPermanently mounting CIFS shares involves configuring your system to automatically connect to these shared resources when the system boots, which is useful when network users need consistent and regular access to them.\nIn this guide, we will show you how to permanently mount and access CIFS shares. The shares can be hosted on a Windows computer/server, or on a Linux/UNIX server running Samba. If you want to know how to host shares, see\nIntroduction to Samba\n.\nPrerequisites\n¶\nIn order to use this guide, you will need to ensure that your network connections have been configured properly. Throughout this guide, we will use the following naming conventions:\nThe local (Ubuntu) username is\nubuntuusername\nThe share username on the Windows computer is\nmsusername\nThe share password on the Windows computer is\nmspassword\nThe Windows computer’s name is\nservername\n(this can be either an IP address or an assigned name)\nThe name of the share is\nsharename\nThe shares are to be mounted in\n/media/windowsshare\nInstall CIFS\n¶\nTo install CIFS, run the following command:\nsudo\napt-get\ninstall\ncifs-utils\nMount unprotected (guest) network folders\n¶\nFirst, let’s create the mount directory. You will need a separate directory for each mount:\nsudo\nmkdir\n/media/windowsshare\nThen edit your\n/etc/fstab\nfile (with root privileges) to add this line:\n//servername/sharename /media/windowsshare cifs guest,uid=1000 0 0\nWhere:\nservername\nis the server\nhostname\nor IP address,\nguest\nindicates you don’t need a password to access the share,\nuid=1000\nmakes the Linux user (specified by the ID) the owner of the mounted share, allowing them to rename files, and\nIf there is any space in the server path, you need to replace it by\n\\040\n, for example:\n//servername/My\\040Documents\nAfter you add the entry to\n/etc/fstab\n, type:\nsudo\nmount\n/media/windowsshare\nMount password-protected network folders\n¶\nTo auto-mount a password-protected share, you can edit\n/etc/fstab\n(with root privileges), and add this line:\n//servername/sharename /media/windowsshare cifs username=msusername,password=mspassword 0 0\nThis is not a good idea however:\n/etc/fstab\nis readable by everyone – and so is your Windows password within it. The way around this is to use a credentials file. This is a file that contains just the username and password.\nCreate a credentials file\n¶\nUsing a text editor, create a file for your remote server’s logon credential:\ngedit\n~/.smbcredentials\nEnter your Windows username and password in the file:\nusername=msusername\n\npassword=mspassword\nSave the file and exit the editor.\nChange the permissions of the file to prevent unwanted access to your credentials:\nchmod\n600\n~/.smbcredentials\nThen edit your\n/etc/fstab\nfile (with root privileges) to add this line (replacing the insecure line in the example above, if you added it):\n//servername/sharename /media/windowsshare cifs credentials=/home/ubuntuusername/.smbcredentials 0 0\nSave the file and exit the editor.\nFinally, test mounting the share by running:\nsudo\nmount\n/media/windowsshare\nIf there are no errors, you should test how it works after a reboot. Your remote share should mount automatically. However, if the remote server goes offline, the boot process could present errors because it won’t be possible to mount the share.\nChanging the share ownership\n¶\nIf you need to change the owner of a share, you’ll need to add a\nUID\n(short for ‘User ID’) or\nGID\n(short for ‘Group ID’) parameter to the share’s mount options:\n//servername/sharename /media/windowsshare cifs uid=ubuntuusername,credentials=/home/ubuntuusername/.smbcredentials 0 0\nMount network folders with authd\n¶\nIf you use Samba and authd at the same time, you must specify user and group mapping. Otherwise, you will encounter permission issues due to mismatched user and group identifiers.\nIf you\nare\nusing Samba with authd, follow the instructions in the\nsteps for the client\nguide in the authd documentation.\nMount password-protected shares using\nlibpam-mount\n¶\nIn addition to the initial assumptions, we’re assuming here that your username and password are the same on both the Ubuntu machine and the network drive.\nInstall\nlibpam-mount\n¶\nsudo\napt-get\ninstall\nlibpam-mount\nEdit\n/etc/security/pam_mount.conf.xml\nusing your preferred text editor.\nsudo\ngedit\n/etc/security/pam_mount.conf.xml\nFirst, we’re moving the user-specific config parts to a file which users can actually edit themselves.\nRemove the commenting tags\n(<!--\nand\n-->)\nsurrounding the section called\n<luserconf\nname=\".pam_mount.conf.xml\"\n/>\n. We also need to enable some extra mount options to be used. For that, edit the “\n<mntoptions\nallow=...\n” tag and add\nuid,gid,dir_mode,credentials\nto it.\nSave the file when done. With this in place, users can create their own\n~/.pam_mount.conf.xml\n.\ngedit\n~/.pam_mount.conf.xml\nAdd the following:\n<?xml version=\"1.0\" encoding=\"utf-8\" ?>\n\n<pam_mount>\n\n<volume options=\"uid=%(USER),gid=100,dir_mode=0700,credentials=/home/ubuntuusername/.smbcredentials,nosuid,nodev\" user=\"*\" mountpoint=\"/media/windowsshare\" path=\"sharename\" server=\"servername\" fstype=\"cifs\" />\n\n</pam_mount>\nTroubleshooting\n¶\nLogin errors\n¶\nIf you get the error “mount error(13) permission denied”, then the server denied your access. Here are the first things to check:\nAre you using a valid username and password? Does that account really have access to this folder?\nDo you have blank space in your credentials file? It should be\npassword=mspassword\n, not\npassword\n=\nmspassword\n.\nDo you need a domain? For example, if you are told that your username is\nSALES\\sally\n, then actually your username is\nsally\nand your domain is\nSALES\n. You can add a\ndomain=SALES\nline to the\n~/.credentials\nfile.\nThe security and version settings are interrelated. SMB1 is insecure and no longer supported. At first, try to not specify either security or version: do not specify\nsec=\nor\nvers=\n. If you still have authentication errors then you may need to specify either\nsec=\nor\nvers=\nor both. You can try the options listed at the\nmount.cifs(8)\nmanual page.\nMount after login instead of boot\n¶\nIf for some reason, such as networking problems, the automatic mounting during boot doesn’t work, you can add the\nnoauto\nparameter to your CIFS\nfstab\nentry and then have the share mounted at login.\nIn\n/etc/fstab\n:\n//servername/sharename /media/windowsshare cifs noauto,credentials=/home/ubuntuusername/.smbpasswd 0 0\nYou can now manually mount the share after you log in. If you would like the share to be automatically mounted after each login, please see the section above about\nlibpam-mount\n.", "meta": {"site": "documentation.ubuntu.com", "crawl_ts": "2025-11-27T10:38:27Z", "original_len_words": 1058}}
{"id": "e34ac70834", "source_url": "https://documentation.ubuntu.com/server/how-to/samba/nt4-domain-controller-legacy/", "title": "NT4 domain controller (legacy) - Ubuntu Server documentation", "text": "NT4 domain controller (legacy) - Ubuntu Server documentation\nContents\nMenu\nExpand\nLight mode\nDark mode\nAuto light/dark, in light mode\nAuto light/dark, in dark mode\nSkip to content\nBack to top\nView this page\nNT4 domain controller (legacy)\n¶\nNote\nThis section is flagged as\nlegacy\nbecause nowadays, Samba can be deployed in full Active Directory domain controller mode, and the old-style NT4 Primary Domain Controller is deprecated.\nA Samba server can be configured to appear as a Windows NT4-style domain controller. A major advantage of this configuration is the ability to centralise user and machine credentials. Samba can also use multiple backends to store the user information.\nPrimary domain controller\n¶\nIn this section, we’ll install and configure Samba as a Primary Domain Controller (PDC) using the default\nsmbpasswd\nbackend.\nInstall Samba\n¶\nFirst, we’ll install Samba, and\nlibpam-winbind\n(to sync the user accounts), by entering the following in a terminal prompt:\nsudo\napt\ninstall\nsamba\nlibpam-winbind\nConfigure Samba\n¶\nNext, we’ll configure Samba by editing\n/etc/samba/smb.conf\n. The\nsecurity\nmode should be set to\nuser\n, and the\nworkgroup\nshould relate to your organization:\nworkgroup = EXAMPLE\n...\nsecurity = user\nIn the commented “Domains” section, add or uncomment the following (the last line has been split to fit the format of this document):\ndomain logons = yes\nlogon path = \\\\%N\\%U\\profile\nlogon drive = H:\nlogon home = \\\\%N\\%U\nlogon script = logon.cmd\nadd machine script = sudo /usr/sbin/useradd -N -g machines -c Machine -d\n      /var/lib/samba -s /bin/false %u\nNote\nIf you wish to not use\nRoaming Profiles\nleave the\nlogon\nhome\nand\nlogon\npath\noptions commented out.\ndomain\nlogons\nProvides the\nnetlogon\nservice, causing Samba to act as a domain controller.\nlogon\npath\nPlaces the user’s Windows profile into their home directory. It is also possible to configure a\n[profiles]\nshare placing all profiles under a single directory.\nlogon\ndrive\nSpecifies the home directory local path.\nlogon\nhome\nSpecifies the home directory location.\nlogon\nscript\nDetermines the script to be run locally once a user has logged in. The script needs to be placed in the\n[netlogon]\nshare.\nadd\nmachine\nscript\nA script that will automatically create the\nMachine Trust Account\nneeded for a workstation to join the domain.\nIn this example the\nmachines\ngroup will need to be created using the\naddgroup\nutility (see\nSecurity - Users: Adding and Deleting Users\nfor details).\nMapping shares\n¶\nUncomment the\n[homes]\nshare to allow the\nlogon\nhome\nto be mapped:\n[homes]\n   comment = Home Directories\n   browseable = no\n   read only = no\n   create mask = 0700\n   directory mask = 0700\n   valid users = %S\nWhen configured as a domain controller, a\n[netlogon]\nshare needs to be configured. To enable the share, uncomment:\n[netlogon]\n   comment = Network Logon Service\n   path = /srv/samba/netlogon\n   guest ok = yes\n   read only = yes\n   share modes = no\nNote\nThe original\nnetlogon\nshare path is\n/home/samba/netlogon\n, but according to the\nFilesystem Hierarchy Standard (FHS)\n,\n/srv is the correct location\nfor site-specific data provided by the system.\nNow create the\nnetlogon\ndirectory, and an empty (for now)\nlogon.cmd\nscript file:\nsudo\nmkdir\n-p\n/srv/samba/netlogon\nsudo\ntouch\n/srv/samba/netlogon/logon.cmd\nYou can enter any normal Windows logon script commands in\nlogon.cmd\nto customize the client’s environment.\nRestart Samba to enable the new domain controller, using the following command:\nsudo\nsystemctl\nrestart\nsmbd.service\nnmbd.service\nFinal setup tasks\n¶\nLastly, there are a few additional commands needed to set up the appropriate rights.\nSince\nroot\nis disabled by default, a system group needs to be mapped to the Windows\nDomain Admins\ngroup in order to join a workstation to the domain. Using the\nnet\nutility, from a terminal enter:\nsudo\nnet\ngroupmap\nadd\nntgroup\n=\n\"Domain Admins\"\nunixgroup\n=\nsysadmin\nrid\n=\n512\ntype\n=\nd\nYou should change\nsysadmin\nto whichever group you prefer. Also, the user joining the domain needs to be a member of the\nsysadmin\ngroup, as well as a member of the system\nadmin\ngroup. The\nadmin\ngroup allows\nsudo\nuse.\nIf the user does not have Samba credentials yet, you can add them with the\nsmbpasswd\nutility. Change the\nsysadmin\nusername appropriately:\nsudo\nsmbpasswd\n-a\nsysadmin\nAlso, rights need to be explicitly provided to the\nDomain Admins\ngroup to allow the\nadd machine script\n(and other admin functions) to work. This is achieved by executing:\nnet\nrpc\nrights\ngrant\n-U\nsysadmin\n\"EXAMPLE\\Domain Admins\"\nSeMachineAccountPrivilege\n\\\nSePrintOperatorPrivilege\nSeAddUsersPrivilege\nSeDiskOperatorPrivilege\n\\\nSeRemoteShutdownPrivilege\nYou should now be able to join Windows clients to the Domain in the same manner as joining them to an NT4 domain running on a Windows server.\nBackup domain controller\n¶\nWith a Primary Domain Controller (PDC) on the network it is best to have a Backup Domain Controller (BDC) as well. This will allow clients to authenticate in case the PDC becomes unavailable.\nWhen configuring Samba as a BDC you need a way to sync account information with the PDC. There are multiple ways of accomplishing this; secure copy protocol (SCP),\nrsync\n, or by using LDAP as the\npassdb\nbackend.\nUsing LDAP is the most robust way to sync account information, because both domain controllers can use the same information in real time. However, setting up an LDAP server may be overly complicated for a small number of user and computer accounts. See\nSamba - OpenLDAP Backend\nfor details.\nFirst, install\nsamba\nand\nlibpam-winbind\n. From a terminal enter:\nsudo\napt\ninstall\nsamba\nlibpam-winbind\nNow, edit\n/etc/samba/smb.conf\nand uncomment the following in the\n[global]\n:\nworkgroup = EXAMPLE\n...\nsecurity = user\nIn the commented\nDomains\nuncomment or add:\ndomain logons = yes\ndomain master = no\nMake sure a user has rights to read the files in\n/var/lib/samba\n. For example, to allow users in the\nadmin\ngroup to SCP the files, enter:\nsudo\nchgrp\n-R\nadmin\n/var/lib/samba\nNext, sync the user accounts, using SCP to copy the\n/var/lib/samba\ndirectory from the PDC:\nsudo\nscp\n-r\nusername@pdc:/var/lib/samba\n/var/lib\nYou can replace\nusername\nwith a valid username and\npdc\nwith the\nhostname\nor IP address of your actual PDC.\nFinally, restart samba:\nsudo\nsystemctl\nrestart\nsmbd.service\nnmbd.service\nYou can test that your Backup Domain Controller is working by first stopping the Samba daemon on the PDC – then try to log in to a Windows client joined to the domain.\nAnother thing to keep in mind is if you have configured the\nlogon\nhome\noption as a directory on the PDC, and the PDC becomes unavailable, access to the user’s\nHome\ndrive will also be unavailable. For this reason it is best to configure the\nlogon\nhome\nto reside on a separate file server from the PDC and BDC.\nFurther reading\n¶\nFor in depth Samba configurations see the\nSamba HOWTO Collection\n.\nThe guide is also available\nin printed format\n.\nO’Reilly’s\nUsing Samba\nis also a good reference.\nChapter 4\nof the Samba HOWTO Collection explains setting up a Primary Domain Controller.\nChapter 5\nof the Samba HOWTO Collection explains setting up a Backup Domain Controller.\nThe\nUbuntu Wiki Samba\npage.", "meta": {"site": "documentation.ubuntu.com", "crawl_ts": "2025-11-27T10:38:28Z", "original_len_words": 1176}}
{"id": "73084c2fb4", "source_url": "https://documentation.ubuntu.com/server/how-to/samba/openldap-backend-legacy/", "title": "OpenLDAP backend (legacy) - Ubuntu Server documentation", "text": "OpenLDAP backend (legacy) - Ubuntu Server documentation\nContents\nMenu\nExpand\nLight mode\nDark mode\nAuto light/dark, in light mode\nAuto light/dark, in dark mode\nSkip to content\nBack to top\nView this page\nOpenLDAP backend (legacy)\n¶\nNote\nThis section is flagged as\nlegacy\nbecause nowadays, Samba 4 is best integrated with its own LDAP server in Active Directory mode. Integrating Samba with LDAP as described here covers the NT4 mode, which has been deprecated for many years.\nThis section covers the integration of Samba with LDAP. The Samba server’s role will be that of a “standalone” server and the LDAP directory will provide the authentication layer in addition to containing the user, group, and machine account information that Samba requires in order to function (in any of its 3 possible roles). The pre-requisite is an OpenLDAP server configured with a directory that can accept authentication requests. See\nInstall LDAP\nand\nLDAP with Transport Layer Security\nfor details on fulfilling this requirement. Once those steps are completed, you will need to decide what specifically you want Samba to do for you and then configure it accordingly.\nThis guide will assume that the LDAP and Samba services are running on the same server and therefore use SASL EXTERNAL authentication whenever changing something under\ncn=config\n. If that is not your scenario, you will have to run those LDAP commands on the LDAP server.\nInstall the software\n¶\nThere are two packages needed when integrating Samba with LDAP:\nsamba\nand\nsmbldap-tools\n.\nStrictly speaking, the\nsmbldap-tools\npackage isn’t needed, but unless you have some other way to manage the various Samba entities (users, groups, computers) in an LDAP context then you should install it.\nInstall these packages now:\nsudo\napt\ninstall\nsamba\nsmbldap-tools\nConfigure LDAP\n¶\nWe will now configure the LDAP server so that it can accommodate Samba data. We will perform three tasks in this section:\nImport a schema\nIndex some entries\nAdd objects\nSamba schema\n¶\nIn order for OpenLDAP to be used as a backend for Samba, the DIT will need to use attributes that can properly describe Samba data. Such attributes can be obtained by introducing a Samba LDAP schema. Let’s do this now.\nThe schema is found in the now-installed samba package and is already in the LDIF format. We can import it with one simple command:\nsudo\nldapadd\n-Q\n-Y\nEXTERNAL\n-H\nldapi:///\n-f\n/usr/share/doc/samba/examples/LDAP/samba.ldif\nTo query and view this new schema:\nsudo\nldapsearch\n-Q\n-LLL\n-Y\nEXTERNAL\n-H\nldapi:///\n-b\ncn\n=\nschema,cn\n=\nconfig\n'cn=*samba*'\nSamba indices\n¶\nNow that\nslapd\nknows about the Samba attributes, we can set up some indices based on them. Indexing entries is a way to improve performance when a client performs a filtered search on the DIT.\nCreate the file\nsamba_indices.ldif\nwith the following contents:\ndn: olcDatabase={1}mdb,cn=config\nchangetype: modify\nreplace: olcDbIndex\nolcDbIndex: objectClass eq\nolcDbIndex: uidNumber,gidNumber eq\nolcDbIndex: loginShell eq\nolcDbIndex: uid,cn eq,sub\nolcDbIndex: memberUid eq,sub\nolcDbIndex: member,uniqueMember eq\nolcDbIndex: sambaSID eq\nolcDbIndex: sambaPrimaryGroupSID eq\nolcDbIndex: sambaGroupType eq\nolcDbIndex: sambaSIDList eq\nolcDbIndex: sambaDomainName eq\nolcDbIndex: default sub,eq\nUsing the\nldapmodify\nutility load the new indices:\nsudo\nldapmodify\n-Q\n-Y\nEXTERNAL\n-H\nldapi:///\n-f\nsamba_indices.ldif\nIf all went well you should see the new indices when using\nldapsearch\n:\nsudo\nldapsearch\n-Q\n-LLL\n-Y\nEXTERNAL\n-H\n\\\nldapi:///\n-b\ncn\n=\nconfig\nolcDatabase\n={\n1\n}\nmdb\nolcDbIndex\nAdding Samba LDAP objects\n¶\nNext, configure the\nsmbldap-tools\npackage to match your environment. The package comes with a configuration helper script called\nsmbldap-config\n. Before running it, though, you should decide on two important configuration settings in\n/etc/samba/smb.conf\n:\nnetbios name\nHow this server will be known. The default value is derived from the server’s\nhostname\n, but truncated at 15 characters.\nworkgroup\nThe workgroup name for this server, or, if you later decide to make it a domain controller, this will be the domain.\nIt’s important to make these choices now because\nsmbldap-config\nwill use them to generate the config that will be later stored in the LDAP directory. If you run\nsmbldap-config\nnow and later change these values in\n/etc/samba/smb.conf\nthere will be an inconsistency.\nOnce you are happy with\nnetbios\nname\nand\nworkgroup\n, proceed to generate the\nsmbldap-tools\nconfiguration by running the configuration script which will ask you some questions:\nsudo\nsmbldap-config\nSome of the more important ones:\nworkgroup name\nHas to match what you will configure in\n/etc/samba/smb.conf\nlater on.\nldap suffix\nHas to match the LDAP suffix you chose when you configured the LDAP server.\nother ldap suffixes\nThey are all relative to\nldap\nsuffix\nabove. For example, for\nldap\nuser\nsuffix\nyou should use\nou=People\n, and for computer/machines, use\nou=Computers\n.\nldap master bind dn\nand\nbind password\nUse the Root\nDN\ncredentials.\nThe\nsmbldap-populate\nscript will then add the LDAP objects required for Samba. It will ask you for a password for the “domain root” user, which is also the “root” user stored in LDAP:\nsudo\nsmbldap-populate\n-g\n10000\n-u\n10000\n-r\n10000\nThe\n-g\n,\n-u\nand\n-r\nparameters tell\nsmbldap-tools\nwhere to start the numeric\nuid\nand\ngid\nallocation for the LDAP users. You should pick a range start that does not overlap with your local\n/etc/passwd\nusers.\nYou can create a LDIF file containing the new Samba objects by executing\nsudo\nsmbldap-populate\n-e\nsamba.ldif\n. This allows you to look over the changes making sure everything is correct. If it is, rerun the script without the\n'-e'\nswitch. Alternatively, you can take the LDIF file and import its data as per usual.\nYour LDAP directory now has the necessary information to authenticate Samba users.\nSamba configuration\n¶\nTo configure Samba to use LDAP, edit its configuration file\n/etc/samba/smb.conf\ncommenting out the default\npassdb\nbackend\nparameter and adding some LDAP-related ones. Make sure to use the same values you used when running\nsmbldap-populate\n:\n#  passdb backend = tdbsam\nworkgroup = EXAMPLE\n    \n# LDAP Settings\npassdb backend = ldapsam:ldap://ldap01.example.com\nldap suffix = dc=example,dc=com\nldap user suffix = ou=People\nldap group suffix = ou=Groups\nldap machine suffix = ou=Computers\nldap idmap suffix = ou=Idmap\nldap admin dn = cn=admin,dc=example,dc=com\nldap ssl = start tls\nldap passwd sync = yes\nChange the values to match your environment.\nNote\nThe\nsmb.conf\nas shipped by the package is quite long and has many configuration examples. An easy way to visualize it without any comments is to run\ntestparm\n-s\n.\nNow inform Samba about the Root DN user’s password (the one set during the installation of the\nslapd\npackage):\nsudo\nsmbpasswd\n-W\nAs a final step to have your LDAP users be able to connect to Samba and authenticate, we need these users to also show up in the system as “Unix” users. Use SSSD for that as detailed in\nNetwork User Authentication with SSSD\n.\nInstall\nsssd-ldap\n:\nsudo\napt\ninstall\nsssd-ldap\nConfigure\n/etc/sssd/sssd.conf\n:\n[\nsssd\n]\nconfig_file_version\n=\n2\ndomains\n=\nexample.com\n[\ndomain/example.com\n]\nid_provider\n=\nldap\nauth_provider\n=\nldap\nldap_uri\n=\nldap://ldap01.example.com\ncache_credentials\n=\nTrue\nldap_search_base\n=\ndc\n=\nexample,dc\n=\ncom\nAdjust permissions and start the service:\nsudo\nchmod\n0600\n/etc/sssd/sssd.conf\nsudo\nchown\nroot:root\n/etc/sssd/sssd.conf\nsudo\nsystemctl\nstart\nsssd\nRestart the Samba services:\nsudo\nsystemctl\nrestart\nsmbd.service\nnmbd.service\nTo quickly test the setup, see if\ngetent\ncan list the Samba groups:\n$\ngetent\ngroup\nReplicators\nReplicators:*:552:\nNote\nThe names are case sensitive!\nIf you have existing LDAP users that you want to include in your new LDAP-backed Samba they will, of course, also need to be given some of the extra Samba specific attributes. The\nsmbpasswd\nutility can do this for you:\nsudo\nsmbpasswd\n-a\nusername\nYou will be prompted to enter a password. It will be considered as the new password for that user. Making it the same as before is reasonable. Note that this command cannot be used to create a new user from scratch in LDAP (unless you are using\nldapsam:trusted\nand\nldapsam:editposix\n, which are not covered in this guide).\nTo manage user, group, and machine accounts use the utilities provided by the\nsmbldap-tools\npackage. Here are some examples:\nTo add a new user with a home directory:\nsudo\nsmbldap-useradd\n-a\n-P\n-m\nusername\nThe\n-a\noption adds the Samba attributes, and the\n-P\noption calls the\nsmbldap-passwd\nutility after the user is created allowing you to enter a password for the user. Finally,\n-m\ncreates a local home directory. Test with the\ngetent\ncommand:\ngetent\npasswd\nusername\nTo remove a user:\nsudo\nsmbldap-userdel\nusername\nIn the above command, use the\n-r\noption to remove the user’s home directory.\nTo add a group:\nsudo\nsmbldap-groupadd\n-a\ngroupname\nAs for\nsmbldap-useradd\n, the\n-a\nadds the Samba attributes.\nTo make an existing user a member of a group:\nsudo\nsmbldap-groupmod\n-m\nusername\ngroupname\nThe\n-m\noption can add more than one user at a time by listing them in comma-separated format.\nTo remove a user from a group:\nsudo\nsmbldap-groupmod\n-x\nusername\ngroupname\nTo add a Samba machine account:\nsudo\nsmbldap-useradd\n-t\n0\n-w\nusername\nReplace\nusername\nwith the name of the workstation. The\n-t\n0\noption creates the machine account without a delay, while the\n-w\noption specifies the user as a machine account.\nResources\n¶\nUpstream documentation collection\nUpstream samba wiki", "meta": {"site": "documentation.ubuntu.com", "crawl_ts": "2025-11-27T10:38:28Z", "original_len_words": 1540}}
{"id": "75c6e3eafc", "source_url": "https://documentation.ubuntu.com/server/how-to/samba/print-server/", "title": "Set up Samba as a print server - Ubuntu Server documentation", "text": "Set up Samba as a print server - Ubuntu Server documentation\nContents\nMenu\nExpand\nLight mode\nDark mode\nAuto light/dark, in light mode\nAuto light/dark, in dark mode\nSkip to content\nBack to top\nView this page\nSet up Samba as a print server\n¶\nAnother common way to network Ubuntu and Windows computers is to configure Samba as a\nprint server\n. This will allow it to share printers installed on an Ubuntu server, whether locally or over the network.\nJust as we did in\nusing Samba as a file server\n, this section will configure Samba to allow any client on the local network to use the installed printers without prompting for a username and password.\nIf your environment requires stricter Access Controls see\nShare Access Control\n.\nInstall and configure CUPS\n¶\nBefore installing and configuring Samba as a print server, it is best to already have a working CUPS installation. See\nour guide on CUPS\nfor details.\nInstall Samba\n¶\nTo install the\nsamba\npackage, run the following command in your terminal:\nsudo\napt\ninstall\nsamba\nConfigure Samba\n¶\nAfter installing\nsamba\n, edit\n/etc/samba/smb.conf\n. Change the\nworkgroup\nattribute to what is appropriate for your network:\nworkgroup = EXAMPLE\nIn the\n[printers]\nsection, change the\nguest ok\noption to ‘yes’:\nbrowsable = yes\nguest ok = yes\nAfter editing\nsmb.conf\n, restart Samba:\nsudo\nsystemctl\nrestart\nsmbd.service\nnmbd.service\nThe default Samba configuration will automatically share any printers installed. Now all you need to do is install the printer locally on your Windows clients.\nFurther reading\n¶\nFor in-depth Samba configurations see the\nSamba HOWTO Collection\n.\nThe guide is also available in\nprinted format\n.\nO’Reilly’s\nUsing Samba\nis another good reference.\nAlso, see the\nCUPS Website\nfor more information on configuring CUPS.\nThe\nUbuntu Wiki Samba\npage.", "meta": {"site": "documentation.ubuntu.com", "crawl_ts": "2025-11-27T10:38:28Z", "original_len_words": 303}}
{"id": "09add709cb", "source_url": "https://documentation.ubuntu.com/server/how-to/samba/provision-samba-ad-controller/", "title": "Provisioning a Samba Active Directory Domain Controller - Ubuntu Server documentation", "text": "Provisioning a Samba Active Directory Domain Controller - Ubuntu Server documentation\nContents\nMenu\nExpand\nLight mode\nDark mode\nAuto light/dark, in light mode\nAuto light/dark, in dark mode\nSkip to content\nBack to top\nView this page\nProvisioning a Samba Active Directory Domain Controller\n¶\nA Samba Active Directory Domain Controller (also known as just Samba AD/DC) is a server running Samba services that can provide authentication to domain users and computers, linux or Windows. It should be dedicated to authentication and authorization services, and not provide file or print services: that should be the role of member servers joined to the domain.\nSee also\nFor more information on why the Samba AD/DC server should not be used to provide file and print services, please refer to this\nlist of reasons and caveats in the Samba Wiki\n.\nThis guide will show how to bootstrap a Samba AD/DC server and verify it’s functioning properly.\nInstallation\n¶\nThis command will install the packages necessary for bootstrapping and testing the Samba AD/DC services:\nsudo apt install samba-ad-dc krb5-user bind9-dnsutils\nNote that the installation of\nkrb5-user\nmight prompt some questions. It’s fine to answer with just the default values (just hit ENTER) at this stage, including when it asks about what the Kerberos realm and servers are.\nNext, we should make sure that the normal Samba services\nsmbd\n,\nnmbd\n, and\nwindind\n, are disabled:\nsudo systemctl disable --now smbd nmbd winbind\nsudo systemctl mask smbd nmbd winbind\nAnd enable the Samba AD/DC service, but without starting it yet:\nsudo systemctl unmask samba-ad-dc\nsudo systemctl enable samba-ad-dc\nNote\nA Samba AD/DC deployment represents a collection of services connected to each other, and needs its own specific systemd service unit.\nThe Samba AD/DC provisioning tool will want to create a new Samba configuration file, dedicated to the AD/DC role, but it will refrain from replacing an existing one. We have to therefore move it away before continuing:\nsudo mv /etc/samba/smb.conf /etc/samba/smb.conf.orig\nProvisioning\n¶\nWith the packages installed, the Samba AD/DC service can be provisioned. For this how-to, we will use the following values:\nDomain:\nEXAMPLE\nRealm:\nEXAMPLE.INTERNAL\nAdministrator password:\nPassw0rd\n(pick your own)\nTo perform the provisioning, run this command:\nsudo samba-tool domain provision \\\n    --domain EXAMPLE \\\n    --realm=EXAMPLE.INTERNAL \\\n    --adminpass=Passw0rd \\\n    --server-role=dc \\\n    --use-rfc2307 \\\n    --dns-backend=SAMBA_INTERNAL\nIf you omit the\n--adminpass\noption, a random password will be chosen and be included in the provisioning output. Be sure to save it!\nWarning\nProviding passwords in the command line is generally unsafe. Other users on the system who can see the process listing can spot the password, and it will also be saved in the shell history, unless the command starts with a blank space.\nThe command will take a few seconds to run, and will output a lot of information. In the end, it should be like this (long lines truncated for better readability):\n(...)\nINFO ... #498: Server Role:     active directory domain controller\nINFO ... #499: Hostname:        ad\nINFO ... #500: NetBIOS Domain:  EXAMPLE\nINFO ... #501: DNS Domain:      example.internal\nINFO ... #502: DOMAIN SID:      S-1-5-21-2373640847-2123283686-338028823\nIf you didn’t use the\n--adminpass\noption, the administrator password will be part of the output above in a line like this:\nINFO ... #497: Admin password:  sbruR-Py>];k=KDn1H58PB#\nPost-installation steps\n¶\nThe AD/DC services are not running yet. Some post-installation steps are necessary before the services can be started.\nFirst, adjust\ndns\nforwarder\nin\n/etc/samba/smb.conf\nto point at your\nDNS\nserver. It will be used for all queries that are not local to the Active Directory domain we just deployed (\nEXAMPLE.INTERNAL\n). The provisioning script simply copied the server IP from\n/etc/resolv.conf\nto this parameter, but if we leave it like that, it will point back to itself:\n[global]\n    dns forwarder = 127.0.0.53\nIf unsure, it’s best to use the current DNS server this system is already using. That can be seen with the\nresolvectl\nstatus\ncommand. Look for the\nCurrent\nDNS\nServer\nline and note the IP address:\nGlobal\n         Protocols: -LLMNR -mDNS -DNSOverTLS DNSSEC=no/unsupported\n  resolv.conf mode: stub\n\nLink 2 (enp5s0)\n    Current Scopes: DNS\n         Protocols: +DefaultRoute -LLMNR -mDNS -DNSOverTLS DNSSEC=no/unsupported\nCurrent DNS Server: 10.10.17.1\n       DNS Servers: 10.10.17.1\n        DNS Domain: lxd\nIn the above example, the DNS server is\n10.10.17.1\n, so that should be used in\n/etc/samba/smb.conf\n’s\ndns\nforwarder\n:\n[global]\n    dns forwarder = 10.10.17.1\nNext, we need to be sure this system will be using the Samba DNS server for its queries, and for that we need to adjust\n/etc/resolv.conf\n. That file will be a symlink, so instead of just rewriting its contents, first we have to remove it:\nsudo unlink /etc/resolv.conf\nNote: this will make sudo issue complaints about DNS from this point on, until the Samba DNS service is up and running.\nAnd now recreate the file\n/etc/resolv.conf\nwith this content:\nnameserver 127.0.0.1\nsearch example.internal\nStop and disable\nsystemd-resolved\nas the resolver will now be using the Samba DNS server directly:\nsudo systemctl disable --now systemd-resolved\nFinally, we need to update\n/etc/krb5.conf\nwith the content generated by the Samba provisioning script. Since this system is dedicated to being a Samba AD/DC server, we can just copy the generated file over:\nsudo cp -f /var/lib/samba/private/krb5.conf /etc/krb5.conf\nIf there are other Kerberos realms involved, you should manually merge the two files.\nWe are now ready to start the Samba AD/DC services:\nsudo systemctl start samba-ad-dc\nAnd this concludes the installation. The next section will show how to perform some basic checks.\nVerification\n¶\nHere are some verification steps that can be run to check that the provisioning was done correctly and the service is ready.\nKerberos authentication\n¶\nA Kerberos ticket for the\nAdministrator\nprincipal can be obtained with the\nkinit\ncommand. Note you don’t have to be\nroot\nto run this command. It’s perfectly fine to get a ticket for a different principal than your own user, even a privileged one:\nkinit Administrator\nThe command will ask for a password. The password is the one supplied to the\nsamba-tool\ncommand earlier, when the domain was provisioned, or the randomly chosen one if the\n--adminpass\noption was not used.\nPassword for Administrator@EXAMPLE.INTERNAL:\nSee also\nIf you are not familiar with Kerberos, please see our\nIntroduction to Kerberos\n.\nTo verify the ticket was obtained, use\nklist\n, which should have output similar to the following:\nTicket cache: FILE:/tmp/krb5cc_1000\nDefault principal: Administrator@EXAMPLE.INTERNAL\n\nValid starting     Expires            Service principal\n07/24/24 13:52:33  07/24/24 23:52:33  krbtgt/EXAMPLE.INTERNAL@EXAMPLE.INTERNAL\n        renew until 07/25/24 13:52:02\nDNS tests\n¶\nUsing the Kerberos ticket from the step above, we can check the DNS server that Samba is running.\nIf everything is correct, the\nhostname\ncommand should be able to return both the short\nhostname\n, and the fully qualified hostname.\nFor the short hostname, use the command:\nhostname\nFor the fully qualified hostname, run this instead:\nhostname -f\nFor example,\nhostname\n-f\nwould return something like\nad.example.internal\n, while\nhostname\nreturns only\nad\n.\nServer Information\n¶\nWith that information at hand and verified, we can perform further checks. Let’s get information about the DNS service provided by this domain controller:\nsamba-tool dns serverinfo $(hostname -f)\nThis command will produce a long output, truncated below:\ndwVersion                   : 0xece0205\nfBootMethod                 : DNS_BOOT_METHOD_DIRECTORY\nfAdminConfigured            : FALSE\nfAllowUpdate                : TRUE\nfDsAvailable                : TRUE\npszServerName               : AD.example.internal\npszDsContainer              : CN=MicrosoftDNS,DC=DomainDnsZones,DC=example,DC=internal\n(...)\nEven though it doesn’t look like it, the\nsamba-tool\ndns\nserverinfo\ncommand used Kerberos authentication. The\nklist\ncommand output now shows another ticket that was obtained automatically:\nTicket cache: FILE:/tmp/krb5cc_1000\nDefault principal: Administrator@EXAMPLE.INTERNAL\n\nValid starting     Expires            Service principal\n07/24/24 14:29:55  07/25/24 00:29:55  krbtgt/EXAMPLE.INTERNAL@EXAMPLE.INTERNAL\n        renew until 07/25/24 14:29:53\n07/24/24 14:29:59  07/25/24 00:29:55  host/ad.example.internal@EXAMPLE.INTERNAL\n        renew until 07/25/24 14:29:53\nA ticket for the\nhost/ad.example.internal@EXAMPLE.INTERNAL\nprincipal is now also part of the ticket cache.\nDNS records\n¶\nThe DNS server backing the Samba Active Directory deployment also needs to have some specific DNS records in its zones, which are needed for service discoverability. Let’s check if they were added correctly with this simple script:\nfor srv in _ldap._tcp _kerberos._tcp _kerberos._udp _kpasswd._udp; do\n    echo -n \"${srv}.example.internal: \"\n    dig @localhost +short -t SRV ${srv}.example.internal\ndone\nThe output should have no errors, and show the DNS records for each query:\n_ldap._tcp.example.internal: 0 100 389 ad.example.internal.\n_kerberos._tcp.example.internal: 0 100 88 ad.example.internal.\n_kerberos._udp.example.internal: 0 100 88 ad.example.internal.\n_kpasswd._udp.example.internal: 0 100 464 ad.example.internal.\nAnd, of course, our own hostname must be in DNS as well:\ndig @localhost +short -t A $(hostname -f)\nThe above command should return your own IP address.\nUser creation test\n¶\nUsers (and groups, and other entities as well) can be created with the\nsamba-tool\ncommand. It can be used remotely, to manage users on a remote Samba AD server, or locally on the same server it is managing.\nWhen run\nlocally as root\n, no further authentication is required:\nsamba-tool user add noble\nThe command above will prompt for the desired password for the\nnoble\nuser, and if it satisfies the password complexity criteria, the user will be created. As with the\nAdministrator\nSamba user,\nkinit\nnoble\ncan be used to test that the\nnoble\nuser can be authenticated.\nNote\nsamba-tool\ncreates\nSamba\nusers, not local Linux users! These Samba users only exist for domain joined computers and other SMB connections/shares.\nThe default password policy is quite severe, requiring complex passwords. To display the current policy, run:\nsudo samba-tool domain passwordsettings show\nWhich will show the default password policy for the domain:\nPassword information for domain 'DC=example,DC=internal'\n\nPassword complexity: on\nStore plaintext passwords: off\nPassword history length: 24\nMinimum password length: 7\nMinimum password age (days): 1\nMaximum password age (days): 42\nAccount lockout duration (mins): 30\nAccount lockout threshold (attempts): 0\nReset account lockout after (mins): 30\nEach one of these can be changed, including the password complexity. For example, to set the minimum password length to 12:\nsudo samba-tool domain passwordsettings set --min-pwd-length=12\nTo see all the options, run:\nsamba-tool domain passwordsettings set --help\nNext steps\n¶\nThis Samba AD/DC server can be treated as an Active Directory server for Window and Linux systems. Typically next steps would be to create users and groups, and join member servers and workstations to this domain. Workstation users would login using the domain credentials, and member servers are used to provide file and print services.\nReferences\n¶\nActive Directory Domain Services Overview\nsamba-tool(8)\nmanual page\nActive Directory integration:\nChoosing an integration method\nJoining a Member Server\nJoining Workstations (without Samba services)", "meta": {"site": "documentation.ubuntu.com", "crawl_ts": "2025-11-27T10:38:28Z", "original_len_words": 1728}}
{"id": "1591ee695b", "source_url": "https://documentation.ubuntu.com/server/how-to/samba/share-access-controls/", "title": "Share access controls - Ubuntu Server documentation", "text": "Share access controls - Ubuntu Server documentation\nContents\nMenu\nExpand\nLight mode\nDark mode\nAuto light/dark, in light mode\nAuto light/dark, in dark mode\nSkip to content\nBack to top\nView this page\nShare access controls\n¶\nThere are several options available to control access for each individual shared directory. Using the\n[share]\nexample, this section will cover some common options.\nSince most of these options will deal with user authentication, we first need to briefly address how that is done in Samba.\nAuthenticating Samba users\n¶\nSamba cannot authenticate existing Linux users using the its native protocols. This is just not compatible with the way Linux passwords are stored in the system (in\n/etc/shadow\n, for example). All local Linux users that the system may have are not automatically available as Samba users. To have a local Linux user available as a Samba user, they need to be created in the Samba credentials database. That means we will have two user databases: the Linux one, and the Samba one.\nSee also\nHow to create and manage Linux users is covered in\nUsers and groups management\n.\nTo add an existing Linux user to the Samba user database, the command\nsmbpasswd\nis used. For example, here we are adding an existing Linux user called\nmelissa\nto the Samba user database:\nsudo smbpasswd -a melissa\nThe command will prompt for a password twice, for confirmation, and create the Samba user.\nNote\nAs this is a separate user database, the password selected for the Samba user does not need to be the same as the Linux password for that user. In fact, most Samba servers setup this way will have the Linux users setup without a valid password: these users only exist so that the corresponding Samba users can be created.\nIf this user does not exist in Linux, the\nsmbpasswd\ncommand will fail. Samba users must first exist as Linux users.\nTo later change the password of an existing Samba user, the same command is used. For example:\nsudo smbpasswd melissa\nSamba also has the concept of Samba groups, but since there is no authentication going on, there is no need to create a separate group database just for Samba groups. We can use the normal Linux group, as long as the group members (the users) exist both in the Linux and Samba user database.\nGroups\n¶\nGroups\ndefine a collection of users who have a common level of access to particular network resources. This provides granularity in controlling access to such resources. For example, let’s consider a group called “qa” is defined to contain the users\nFreda\n,\nDanika\n, and\nRob\n,  and then a group called “support” is created containing the users\nDanika\n,\nJeremy\n, and\nVincent\n. Any network resources configured to allow access by the “qa” group will be available to Freda, Danika, and Rob, but not Jeremy or Vincent. Danika can access resources available to both groups since she belongs to both the “qa” and “support” groups. All other users only have access to resources explicitly allowed to the group they are part of.\nWhen mentioning groups in the Samba configuration file,\n/etc/samba/smb.conf\n, the recognized syntax is to preface the group name with an “@” symbol. For example, if you wished to use a group named\nsysadmin\nin a certain section of the\n/etc/samba/smb.conf\n, you would do so by entering the group name as\n@sysadmin\n. If a group name has a space in it, use double quotes, like\n\"@LTS\nReleases\"\n.\nRead and write permissions\n¶\nRead and write permissions define the explicit rights a computer or user has to a particular share. Such permissions may be defined by editing the\n/etc/samba/smb.conf\nfile and specifying the explicit permissions inside a share.\nFor example, if you have defined a Samba share called\nshare\nand wish to give read-only permissions to the group of users known as “qa”, but wanted to allow writing to the share by the group called “sysadmin”\nand\nthe user named “vincent”, then you could edit the\n/etc/samba/smb.conf\nfile and add the following entries under the\n[share]\nentry:\nread list = @qa\nwrite list = @sysadmin, vincent\nAnother possible Samba permission is to declare\nadministrative\npermissions to a particular shared resource. Users having administrative permissions may read, write, or modify any information contained in the resource the user has been given explicit administrative permissions to.\nFor example, if you wanted to give the user\nMelissa\nadministrative permissions to the\nshare\nexample, you would edit the\n/etc/samba/smb.conf\nfile, and add the following line under the\n[share]\nentry:\nadmin users = melissa\nNote\nRemember that the users listed in\nsmb.conf\nfor these access controls need to exist both as Linux users, and Samba users.\nAfter editing\n/etc/samba/smb.conf\n, reload Samba for the changes to take effect by running the following command:\nsudo\nsmbcontrol\nsmbd\nreload-config\nFilesystem permissions\n¶\nNow that Samba has been configured to limit which groups have access to the shared directory, the\nfilesystem\npermissions need to be checked.\nTraditional Linux file permissions do not map well to Windows NT Access Control Lists (\nACL\ns). Fortunately POSIX ACLs are available on Ubuntu servers, which provides more fine-grained control. For example, to enable ACLs on\n/srv\nin an EXT3 filesystem, edit\n/etc/fstab\nand add the\nacl\noption:\nUUID=66bcdd2e-8861-4fb0-b7e4-e61c569fe17d /srv  ext3    noatime,relatime,acl 0       1\nThen remount the partition:\nsudo\nmount\n-v\n-o\nremount\n/srv\nNote\nThis example assumes\n/srv\nis on a separate partition. If\n/srv\n, or wherever you have configured your share path, is part of the\n/\npartition then a reboot may be required.\nTo match the Samba configuration above, the “sysadmin” group will be given read, write, and execute permissions to\n/srv/samba/share\n, the “qa” group will be given read and execute permissions, and the files will be owned by the username “Melissa”. Enter the following in a terminal:\nsudo\nchown\n-R\nmelissa\n/srv/samba/share/\nsudo\nchgrp\n-R\nsysadmin\n/srv/samba/share/\nsudo\nsetfacl\n-R\n-m\ng:qa:rx\n/srv/samba/share/\nNote\nThe\nsetfacl\ncommand above gives\nexecute\npermissions to all files in the\n/srv/samba/share\ndirectory, which you may or may not want.\nNow from a Windows client you should notice the new file permissions are implemented. See the\nacl(5)\nand\nsetfacl(1)\nmanual pages for more information on POSIX ACLs.\nFurther reading\n¶\nFor in-depth Samba configurations see the\nSamba HOWTO Collection\n.\nThe guide is also available in\nprinted format\n.\nO’Reilly’s\nUsing Samba\nis also a good reference.\nChapter 18\nof the Samba HOWTO Collection is devoted to security.\nFor more information on Samba and ACLs see the\nSamba ACLs page\n.\nThe\nUbuntu Wiki Samba\npage.", "meta": {"site": "documentation.ubuntu.com", "crawl_ts": "2025-11-27T10:38:29Z", "original_len_words": 1107}}
{"id": "0ece89b903", "source_url": "https://documentation.ubuntu.com/server/how-to/security/", "title": "Security - Ubuntu Server documentation", "text": "Security - Ubuntu Server documentation\nContents\nMenu\nExpand\nLight mode\nDark mode\nAuto light/dark, in light mode\nAuto light/dark, in dark mode\nSkip to content\nBack to top\nView this page\nSecurity\n¶\nWhile a fresh Ubuntu installation is usually safe for immediate use, there are some additional steps you can take to introduce a layered approach to your system’s security. If you are new to Ubuntu, you may want to refer to our\nIntroduction to security\nfirst for a general overview.\nGeneral configuration\n¶\nUsers and groups management\nfor setting up user accounts, permissions and password policies\nFirewalls\nare recommended for network security\nAppArmor\nlimits permissions and access for the software running on your system\nConsole security\nfor an additional physical security barrier\nAuthentication\n¶\nThese tools are particularly useful for more advanced or complex setups.\nKerberos\nis a network authentication protocol providing identity verification for distributed systems\nNetwork user authentication with SSSD\nhandles authentication, user/group information and authorisation from disparate network sources\nSmart card authentication\nprovides a physical authentication method\nCryptography\n¶\nThe Secure Shell (SSH) cryptographic protocol that provides secure channels on an unsecured network. In Ubuntu, OpenSSH is the most commonly used implementation of SSH. It provides a suite of utilities for encrypting data transfers and can also be used for remote login and authentication.\nOpenSSH\nOpenSSH server\n2FA with TOTP/HOTP\n2FA with U2F/FIDO\nInstall a root CA certificate\nVirtual Private Network (VPN)\n¶\nVPNs are commonly used to provide encrypted, secure access to a network. Two of the most popular choices in Ubuntu are OpenVPN and WireGuard VPN.\nOpenVPN\nis a well-established option that supports many platforms besides Linux\nWireGuard VPN\nis a modern and performant option that removes a lot of the complexity from configuring a VPN\nSee also\n¶\nExplanation:\nIntroduction to security\nExplanation:\nSecurity topics", "meta": {"site": "documentation.ubuntu.com", "crawl_ts": "2025-11-27T10:38:29Z", "original_len_words": 303}}
{"id": "4268d9de49", "source_url": "https://documentation.ubuntu.com/server/how-to/software/", "title": "Managing software - Ubuntu Server documentation", "text": "Managing software - Ubuntu Server documentation\nContents\nMenu\nExpand\nLight mode\nDark mode\nAuto light/dark, in light mode\nAuto light/dark, in dark mode\nSkip to content\nBack to top\nView this page\nManaging software\n¶\nPackage management\nshows you how to manage the software on your system using APT, dpkg, and other package managers\nUpdates\n¶\nAutomatic updates\nshows you how to configure (or turn off) automatic updates\nUpgrade your release\nshows you how to upgrade from one Ubuntu release to the next one\nSnapshot service\nshows you how to use the Ubuntu Snapshot Service to update packages to time-specific archive states.\nTroubleshooting\n¶\nReporting bugs\nshows you how to report a bug using the Apport utility\nKernel crash dump\nshows how to use the kernel crash dump utility\nSee also\n¶\nExplanation:\nManaging software", "meta": {"site": "documentation.ubuntu.com", "crawl_ts": "2025-11-27T10:38:29Z", "original_len_words": 135}}
{"id": "518ede3019", "source_url": "https://documentation.ubuntu.com/server/how-to/software/automatic-updates/", "title": "Automatic updates - Ubuntu Server documentation", "text": "Automatic updates - Ubuntu Server documentation\nContents\nMenu\nExpand\nLight mode\nDark mode\nAuto light/dark, in light mode\nAuto light/dark, in dark mode\nSkip to content\nBack to top\nView this page\nAutomatic updates\n¶\nUbuntu will apply security updates automatically, without user interaction. This is done via the\nunattended-upgrades\npackage, which is installed by default.\nBut as the name suggests, it can apply other types of updates, and with interesting options alongside. For example:\nIt can reboot the system, if an update warrants it.\nIt can apply other types of updates, not just security.\nIt can block certain updates from ever being applied automatically.\nAnd more. Let’s explore some of these options.\nImportant\nJust adding another package repository to an Ubuntu system WILL NOT make\nunattended-upgrades\nconsider it for updates! This is explained in\nwhere to pick updates from\nlater in this document.\nConfiguration layout\n¶\nIf for some reason the package is not present, it can be installed with the following command:\nsudo\napt\ninstall\nunattended-upgrades\nImportant files and directories:\n/etc/apt/apt.conf.d/50unattended-upgrades\n: This file contains the options that control the behavior of the tool, such as if a reboot should be scheduled or not, or which packages are blocked from being upgraded.\n/etc/apt/apt.conf.d/20auto-upgrades\n: This file is used to control whether the unattended upgrade should be enabled or not, and how often it should run.\n/var/log/unattended-upgrades\n: This directory contains detailed logs of each unattended upgrade run.\nRight after installation, automatic installation of security updates will be enabled, including\nExpanded Security Maintenance (ESM)\nif that is available on the system. By default,\nunattended-upgrades\nruns once per day.\nEnabling and disabling unattended upgrades\n¶\nUnattended upgrades performs the equivalent of\napt\nupdate\nand\napt\nupgrade\n(see\nUpgrading packages\nfor details on these commands. First, it refreshes the package lists, to become aware of the new state of the package repositories. Then it checks which upgrades are available and applies them.\nThese two steps are controlled via the\nUpdate-Package-Lists\nand\nUnattended-Upgrade\noptions in\n/etc/apt/apt.conf.d/20auto-upgrades\n:\nAPT::Periodic::Update-Package-Lists \"1\";\nAPT::Periodic::Unattended-Upgrade \"1\";\nEach option accepts a time-based value, representing the number of days. A value of\n0\ndisables the action. The default value,\n1\n, executes the action daily. A value of\n2\nexecutes it every two days, and so forth.\nTherefore, to disable unattended upgrades, set these options to zero:\nAPT::Periodic::Update-Package-Lists \"0\";\nAPT::Periodic::Unattended-Upgrade \"0\";\nSystemd timer units,\napt-daily.timer\nand\napt-daily-upgrade.timer\n, trigger these actions at a scheduled time with a random delay. These timers activate services that execute the\n/usr/lib/apt/apt.systemd.daily\nscript.\nHowever, it may happen that if the machine is off at the time the timer unit elapses, the timer may be triggered immediately at the next startup (still subject to the\nRandomizedDelaySec\nvalue). As a result,\nunattended-upgrades\nmay often run on system startup and thereby cause immediate activity and prevent other package operations from taking place at that time. For example, if another package has to be installed, it would have to wait until the upgrades are completed.\nIn many cases this is beneficial, but in some cases it might be counter-productive; examples are administrators with many shut-down machines or VM images that are only started for some quick action, which is delayed or even blocked by the unattended upgrades. To change this behavior, we can change/override the configuration of both APT’s timer units\napt-daily-upgrade.timer\nand\napt-daily.timer\n. To do so, use\nsystemctl\nedit\n<timer_unit>\nand override the\nPersistent\nattribute setting it to\nfalse\n:\n[Timer]\nPersistent\n=\nfalse\nWith this change, the timer will trigger the service only on the next scheduled time. In other words, it won’t catch up to the run it missed while the system was off. See the explanation for the\nPersistent\noption in\nsystemd.timer(5)\nmanpage for more details.\nWhere to pick updates from\n¶\nIn\n/etc/apt/apt.conf.d/50unattended-upgrades\n, the\nAllowed-Origins\nsection specifies which repositories will be used to gather updates from. See the\nUbuntu Packaging Guide\nfor additional information about each official repository that Ubuntu uses.\nThis is the default:\nUnattended-Upgrade::Allowed-Origins {\n    \"${distro_id}:${distro_codename}\";\n    \"${distro_id}:${distro_codename}-security\";\n    // Extended Security Maintenance; doesn't necessarily exist for\n    // every release and this system may not have it installed, but if\n    // available, the policy for updates is such that unattended-upgrades\n    // should also install from here by default.\n    \"${distro_id}ESMApps:${distro_codename}-apps-security\";\n    \"${distro_id}ESM:${distro_codename}-infra-security\";\n//  \"${distro_id}:${distro_codename}-updates\";\n//  \"${distro_id}:${distro_codename}-proposed\";\n//  \"${distro_id}:${distro_codename}-backports\";\n};\nNote\nThe double “//” indicates a comment, so whatever follows “//” will not be evaluated.\nIf you want to also allow non-security updates to be applied automatically, then uncomment the line about\n-updates\n, like so:\nUnattended-Upgrade::Allowed-Origins {\n    \"${distro_id}:${distro_codename}\";\n    \"${distro_id}:${distro_codename}-security\";\n    // Extended Security Maintenance; doesn't necessarily exist for\n    // every release and this system may not have it installed, but if\n    // available, the policy for updates is such that unattended-upgrades\n    // should also install from here by default.\n    \"${distro_id}ESMApps:${distro_codename}-apps-security\";\n    \"${distro_id}ESM:${distro_codename}-infra-security\";\n    \"${distro_id}:${distro_codename}-updates\";\n//  \"${distro_id}:${distro_codename}-proposed\";\n//  \"${distro_id}:${distro_codename}-backports\";\n};\nThe\nOrigin\nfield is a standard field used in package repositories. By default,\nunattended-upgrades\nwill ship with only official Ubuntu repositories configured, which is the configuration shown above. To have the system apply upgrades automatically from other repositories, its\nOrigin\nneeds to be added to this configuration option.\nAutomatic upgrades from a PPA\n¶\nA very popular package repository type is a\nLaunchpad PPA\n. PPAs are normally referred to using the format\nppa:\\<user\\>/\\<name\\>\n. For example, the PPA at\nhttps://launchpad.net/~canonical-server/+archive/ubuntu/server-backports\nis also referred to as\nppa:canonical-server/server-backports\n.\nTo use a PPA in the\nAllowed-Origins\nconfiguration, we need its\nOrigin\nfield. For PPAs, it is in the format\nLP-PPA-<user>-<name>\n. Adding it to the\nAllowed-Origins\nconfiguration would result in the following (continuing from the example above):\nUnattended-Upgrade::Allowed-Origins {\n    \"${distro_id}:${distro_codename}\";\n    \"${distro_id}:${distro_codename}-security\";\n    // Extended Security Maintenance; doesn't necessarily exist for\n    // every release and this system may not have it installed, but if\n    // available, the policy for updates is such that unattended-upgrades\n    // should also install from here by default.\n    \"${distro_id}ESMApps:${distro_codename}-apps-security\";\n    \"${distro_id}ESM:${distro_codename}-infra-security\";\n    \"${distro_id}:${distro_codename}-updates\";\n//  \"${distro_id}:${distro_codename}-proposed\";\n//  \"${distro_id}:${distro_codename}-backports\";\n    \"LP-PPA-canonical-server-server-backports:${distro_codename}\";\n};\nDue to the hyphens acting as both separators and part of the name, the complete configuration can become visually confusing, making it difficult to immediately distinguish between the username and PPA name. But that’s ok, because it’s the whole text that matters.\nNow when the tool runs, that PPA will be considered for upgrades and is listed in\nAllowed origins\n:\n2025-03-13 22:44:29,802 INFO Starting unattended upgrades script\n2025-03-13 22:44:29,803 INFO Allowed origins are: o=Ubuntu,a=noble, o=Ubuntu,a=noble-security, o=UbuntuESMApps,a=noble-apps-security, o=UbuntuESM,a=noble-infra-security, o=LP-PPA-canonical-server-server-backports,a=noble\n2025-03-13 22:44:29,803 INFO Initial blacklist:\n2025-03-13 22:44:29,803 INFO Initial whitelist (not strict):\n2025-03-13 22:44:33,029 INFO Option --dry-run given, *not* performing real actions\n2025-03-13 22:44:33,029 INFO Packages that will be upgraded: ibverbs-providers libibverbs1 rdma-core\n2025-03-13 22:44:33,029 INFO Writing dpkg log to /var/log/unattended-upgrades/unattended-upgrades-dpkg.log\n2025-03-13 22:44:34,421 INFO All upgrades installed\n2025-03-13 22:44:34,855 INFO The list of kept packages can't be calculated in dry-run mode.\nThe correct\nOrigin\nvalue to use is available in the repository’s\nInRelease\n(or, for older formats, the\nRelease\nfile), which can be found at the URL of the repository, or locally on the system after an\napt\nupdate\ncommand was run. Locally these files are in the\n/var/lib/apt/lists/\ndirectory. For example, for the PPA case, we have:\n/var/lib/apt/lists/ppa.launchpadcontent.net_canonical-server_server-backports_ubuntu_dists_noble_InRelease\nWhich has contents:\n-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA512\n\nOrigin: LP-PPA-canonical-server-server-backports\nLabel: Server Team Backports\nSuite: noble\nVersion: 24.04\nCodename: noble\nDate: Tue, 03 Dec 2024  6:00:43 UTC\nArchitectures: amd64 arm64 armhf i386 ppc64el riscv64 s390x\nComponents: main\nDescription: Ubuntu Noble 24.04\n(...)\nAnd there we can see the\nOrigin\n.\nHow to block certain packages\n¶\nSpecific packages can also be excluded from an update. This is controlled via the\nUnattended-Upgrade::Package-Blacklist\nconfiguration option in\n/etc/apt/apt.conf.d/50unattended-upgrades\n, which contains a list of\nPython Regular Expressions\n. Each line of this list is checked against the available package updates, and if there is a match, that package is not upgraded.\nNote\nKeep in mind that blocking a package might prevent other updates from being installed if they depend on the blocked package!\nFor example, this will block all packages that start with\nlinux-\nfrom being automatically upgraded:\nUnattended-Upgrade::Package-Blacklist {\n    \"linux-\";\n}\nA more specific configuration like the one below will block only the\nlibc6\nand\nlibc-bin\npackages from being automatically upgraded:\nUnattended-Upgrade::Package-Blacklist {\n    \"libc6$\";\n    \"libc-bin$\";\n}\nHere, the use of the\n$\ncharacter marks the end of the package name (in regular expression terms, it’s the end of the line, i.e., the end of the match).\nNote\nThe regular expressions used here behave as if the “\n^\n” character is present at the start, i.e., the\nlibc6$\nexpression will match\nlibc6\n, but will NOT match\nglibc6\nfor example.\nOf course, this being a regular expression means we could also write the above like this:\nUnattended-Upgrade::Package-Blacklist {\n    \"libc(6|-bin)$\";\n}\nJust be careful to not overuse the power of regular expressions: readability is key.\nNotifications\n¶\nBesides logging,\nunattended-upgrades\ncan also send out reports via email. There are two options that control this behavior in\n/etc/apt/apt.conf.d/50unattended-upgrades\n:\nUnattended-Upgrade::Mail\n\"user@example.com\";\n: If set to an email address, this option will trigger an email to this address containing an activity report. When this value is empty, or not set, (which is the default), no report is sent.\nUnattended-Upgrade::MailReport\n\"on-change\";\n: This option controls when a report is sent:\nalways\n: Always send a report, regardless if upgrades were applied or not.\nonly-on-error\n: Only send a report if there was an error.\non-change\n: Only send a report if upgrades were applied. This is the default value.\nNote\nSending out emails like this requires the separate configuration of a package like\nssmtp(8)\nor another minimalistic mail client that is capable of sending messages to a mail server.\nNotification examples\n¶\nHere are some email examples (lines wrapped for better legibility).\nNo changes applied, no errors\n¶\nThis would only be sent if\nUnattended-Upgrade::MailReport\nis set to\nalways\n:\nSubject:\nunattended-upgrades\nresult\nfor\n<hostname>:\nSUCCESS\n\nUnattended upgrade result: No packages found that can be upgraded\n unattended and no pending auto-removals\n\nUnattended-upgrades log:\nStarting unattended upgrades script\nAllowed origins are: o=Ubuntu,a=noble, o=Ubuntu,a=noble-security,\n o=UbuntuESMApps,a=noble-apps-security,\n o=UbuntuESM,a=noble-infra-security, o=Ubuntu,a=noble,\n o=Ubuntu,a=noble-security, o=UbuntuESMApps,a=noble-apps-security,\n o=UbuntuESM,a=noble-infra-security\nInitial blacklist:\nInitial whitelist (not strict):\nNo packages found that can be upgraded unattended and no pending auto-removals\nUpgrades applied, no errors\n¶\nThis is the default email report, when\nUnattended-Upgrade::MailReport\nis set to\non-change\n:\nSubject:\nunattended-upgrades\nresult\nfor\nnuc1:\nSUCCESS\n\nUnattended upgrade result: All upgrades installed\n\nPackages that were upgraded:\n linux-firmware\n\nPackage installation log:\nLog started: 2025-03-13  06:19:10\nPreparing to unpack\n .../linux-firmware_20240318.git3b128b60-0ubuntu2.10_amd64.deb ...\nUnpacking linux-firmware (20240318.git3b128b60-0ubuntu2.10) over\n (20240318.git3b128b60-0ubuntu2.9) ...\nSetting up linux-firmware (20240318.git3b128b60-0ubuntu2.10) ...\nProcessing triggers for initramfs-tools (0.142ubuntu25.5) ...\nupdate-initramfs: Generating /boot/initrd.img-6.8.0-55-generic\n\nRunning kernel seems to be up-to-date.\n\nThe processor microcode seems to be up-to-date.\n\nNo services need to be restarted.\n\nNo containers need to be restarted.\n\nNo user sessions are running outdated binaries.\n\nNo VM guests are running outdated hypervisor (qemu) binaries on this host.\nLog ended: 2025-03-13  06:19:26\n\n\n\nUnattended-upgrades log:\nStarting unattended upgrades script\nAllowed origins are: o=Ubuntu,a=noble, o=Ubuntu,a=noble-security,\n o=UbuntuESMApps,a=noble-apps-security,\n o=UbuntuESM,a=noble-infra-security, o=Ubuntu,a=noble,\n o=Ubuntu,a=noble-security, o=UbuntuESMApps,a=noble-apps-security,\n o=UbuntuESM,a=noble-infra-security\nInitial blacklist:\nInitial whitelist (not strict):\nPackages that will be upgraded: linux-firmware\nWriting dpkg log to /var/log/unattended-upgrades/unattended-upgrades-dpkg.log\nAll upgrades installed\nReboots\n¶\nSometimes a system needs to be rebooted to fully apply an update. Such updates can use a mechanism in Ubuntu to let the system know that a reboot is recommended.\nunattended-upgrades\ncan benefit from this mechanism and optionally reboot the system automatically when needed.\nReboots can be very disruptive, especially if the system fails to come back. There are some configuration options where this behavior can be adjusted:\nUnattended-Upgrade::Automatic-Reboot\n\"false\";\n: If this option is set to\ntrue\n, the system will be rebooted\nwithout confirmation\nat the end of an upgrade run if a reboot was requested. The default value is\nfalse\n.\nUnattended-Upgrade::Automatic-Reboot-WithUsers\n\"true\";\n: Automatically reboot even if there are users currently logged in when\nUnattended-Upgrade::Automatic-Reboot\n(the option above) is set to\ntrue\n. The default value is\ntrue\n.\nUnattended-Upgrade::Automatic-Reboot-Time\n\"now\";\n: If automatic reboot is enabled and needed, reboot at the specific time instead of immediately. The time value is passed as-is to the\nshutdown(8)\ncommand. It can be the text “now” (which is the default), or in the format “hh:mm” (hours:minutes), or an offset in minutes specified like “+m”. Note that if using “hh:mm”, it will be in the local system’s timezone.\nNote\nFor more information about this time specification for the reboot, and other options like cancelling a scheduled reboot, see the\nshutdown(8)\nmanpage.\nBelow are the logs of an\nunattended-upgrades\nrun that started at 20:43. The tool installed the available upgrades and detected that a reboot was requested, which was scheduled using the configured\nAutomatic-Reboot-Time\n(20:45 in this example):\n2025-03-13 20:43:25,923 INFO Starting unattended upgrades script\n2025-03-13 20:43:25,924 INFO Allowed origins are: o=Ubuntu,a=noble, o=Ubuntu,a=noble-security, o=UbuntuESMApps,a=noble-apps-security, o=UbuntuESM,a=noble-infra-security\n2025-03-13 20:43:25,924 INFO Initial blacklist:\n2025-03-13 20:43:25,924 INFO Initial whitelist (not strict):\n2025-03-13 20:43:29,082 INFO Packages that will be upgraded: libc6 python3-jinja2\n2025-03-13 20:43:29,082 INFO Writing dpkg log to /var/log/unattended-upgrades/unattended-upgrades-dpkg.log\n2025-03-13 20:43:39,532 INFO All upgrades installed\n2025-03-13 20:43:40,201 WARNING Found /var/run/reboot-required, rebooting\n2025-03-13 20:43:40,207 WARNING Shutdown msg: b\"Reboot scheduled for Thu 2025-03-13 20:45:00 UTC, use 'shutdown -c' to cancel.\"\nWhen to consider disabling automatic updates\n¶\nWhile automatic security updates are enabled in Ubuntu by default, in some situations it might make sense to disable this feature, or carefully limit its reach.\nHere are some considerations.\nSystems which just get recreated\n¶\nSome systems are designed to be redeployed from a new base image rather than receive updates. This is common in cloud and container-based applications, where outdated instances are destroyed and replaced with newer ones. These systems are typically very lean, focused solely on running specific applications, and so may lack self-update tools.\nKeep in mind that the security exposure is still there: it’s only the update mechanism that is different, and comes in the form of a new deployment. The update still has to happen somewhere, it’s just not at runtime. Until that new deployment is done, outdated software might still be running.\nManual steps required\n¶\nWhile Ubuntu updates rarely require manual steps to complete an upgrade (at most a reboot can be required), it could be plausible that other applications require some manual steps after or before an update is applied. If that is the case, and if such steps cannot be safely automated, then maybe\nunattended-upgrades\nshould be disabled on such systems.\nDo consider block-listing such packages instead, if they are known to trigger such manual steps. In that case, the system can still benefit from all the other upgrades that might become available.\nToo much of a risk\n¶\nEven with all the care in the world, applying updates to a running system comes with risk. Ubuntu believes that risk to be less than the risk of NOT applying a security update, which is why\nunattended-upgrades\nwill apply security updates by default. But for some specific systems, the risk vs benefit equation might favor staying put and not applying an update unless specifically requested.\nAlways keep in mind, however, that specific packages can be blocked from receiving updates. For example, if a particular system runs a critical application that could break if certain libraries on the system are updated, then perhaps an acceptable compromise is to block these library packages from receiving upgrades, instead of disabling the whole feature.\nAs a middle-ground solution, you can configure\nunattended-upgrades\nto postpone impending updates to a later time. Read how to configure this feature in the\nPostponable updates\nsection.\nFleet management\n¶\nThe\nunattended-upgrades\nfeature is helpful, does its job, and even sends out reports. But it’s not intended to be a replacement for fleet management software. If a large number of Ubuntu systems needs to be kept updated, other solutions are better suited for the job. Such large deployments usually come with much stricter and wider requirements, like:\nCompliance reports: How many systems are up-do-date, how many are still behind, for how long has a system been exposed to a known vulnerability, etc.\nMaintenance windows: Different systems might require different maintenance windows. Some can be updated anytime, others only on weekends, etc.\nCanary rollouts: The ability to rollout updates to an initial group of systems, and over time increase the number of systems that will receive the update.\nAn example of such a Fleet Management software for Ubuntu systems is\nLandscape\n.\nPostponable updates\n¶\nBy default, system updates are applied automatically in the background without any user interaction.\nStarting with Ubuntu 25.04, a system administrator can allow users to postpone these automatic updates for a limited number of days by setting the\nUnattended-Update::Postpone-For-Days\noption.\nWhen this option is set,\nunattended-upgrade\nwill run according to the cadence set by the administrator and check for updates. If there are updates available it will notify active users and prompt them to choose if they want to upgrade immediately, or postpone them. For example, if\nUnattended-Upgrade::Postpone-For-Days\n\"3\"\nis set, then the user can postpone upgrades for up to three days. After that, the next time\nunattended-updates\nruns the user will not be prompted and the upgrades will be applied to the system.\nTo enable the feature, edit the\n/etc/apt/apt.conf.d/50unattended-upgrades\nfile and set the number of days that a user is allowed to postpone the automatic updates for. To postpone for up to\n3\ndays:\nUnattended-Upgrade::Postpone-For-Days \"3\";\nTo disable the feature, set the number of days to\n0\n.\nPrompt duration\n¶\nThe\nUnattended-Upgrade::Postpone-Wait-Time\nconfiguration option controls the amount of time (in seconds) that a user has available to send a postpone request after being prompted. If no postpone request is received within the specified time, the updates will start being applied as normal.\nWho can postpone\n¶\nThe system administrator can restrict access to the postpone request by defining Polkit rules for the\ncom.ubuntu.UnattendedUpgrade.Pending.Postpone\naction. By default, access is granted to users of an active session. See the\npolkit documentation\nfor how to set up authorization rules.\nNotifications in different environments\n¶\nThe prompting functionality is implemented graphically on Ubuntu Desktop by the\nupdate-notifier\nprogram. The user is shown a notification with the option to postpone the updates. Then, while updates are being applied an icon is visible in the system tray area informing the user so they know when it is safe to resume critical activities that may be affected by the updates.\nOn other environments, such as Ubuntu Server, you can implement your own prompting client by listening for the\nAboutToStart\nsignal on the system bus and send a call to the\nPostpone()\nmethod. Read the\n/usr/share/dbus-1/interfaces/com.ubuntu.UnattendedUpgrade.Pending.xml\ninterface specification for more details.\nTesting and troubleshooting\n¶\nIt’s possible to test some configuration changes to\nunattended-upgrade\nwithout having to wait for the next time it would run. The\nunattended-upgrade\ntool has a\nmanual page\nthat explains all its command-line options. Here are the most useful ones for testing and troubleshooting:\n-v\n: Show a more verbose output.\n--dry-run\n:  Just simulate what would happen, without actually making any changes.\nFor example, let’s say we want to check if the PPA origin was included correctly in the\nAllowed-Origins\nconfiguration, and if an update that we know is available would be considered.\nAfter we add\n\"LP-PPA-canonical-server-server-backports:${distro_codename}\";\nto\nAllowed-Origins\nin\n/etc/apt/apt.conf.d/50unattended-upgrades\n, we can run the tool in\nverbose\nand\ndry-run\nmodes to check what would happen:\nsudo\nunattended-upgrade\n-v\n--dry-run\nWhich produces the following output, in this example scenario:\nStarting unattended upgrades script\nAllowed origins are: o=Ubuntu,a=noble, o=Ubuntu,a=noble-security, o=UbuntuESMApps,a=noble-apps-security, o=UbuntuESM,a=noble-infra-security, o=LP-PPA-canonical-server-server-backports,a=noble\nInitial blacklist:\nInitial whitelist (not strict):\nOption --dry-run given, *not* performing real actions\nPackages that will be upgraded: rdma-core\nWriting dpkg log to /var/log/unattended-upgrades/unattended-upgrades-dpkg.log\n/usr/bin/unattended-upgrade:567: DeprecationWarning: This process (pid=1213) is multi-threaded, use of fork() may lead to deadlocks in the child.\n  pid = os.fork()\n/usr/bin/dpkg --status-fd 10 --no-triggers --unpack --auto-deconfigure /var/cache/apt/archives/rdma-core_52.0-2ubuntu1~backport24.04.202410192216~ubuntu24.04.1_amd64.deb\n/usr/bin/dpkg --status-fd 10 --configure --pending\nAll upgrades installed\nThe list of kept packages can't be calculated in dry-run mode.\nOf note, we see:\nAllowed\norigins\ninclude\no=LP-PPA-canonical-server-server-backports,a=noble\n, which is the PPA we included.\nThe\nrdma-core\npackage would be updated.\nLet’s check this\nrdma-core\npackage with the command\napt-cache\npolicy\nrdma-core\n:\nrdma-core:\n  Installed: 50.0-2build2\n  Candidate: 52.0-2ubuntu1~backport24.04.202410192216~ubuntu24.04.1\n  Version table:\n     52.0-2ubuntu1~backport24.04.202410192216~ubuntu24.04.1 500\n        500 https://ppa.launchpadcontent.net/canonical-server/server-backports/ubuntu noble/main amd64 Packages\n *** 50.0-2build2 500\n        500 http://br.archive.ubuntu.com/ubuntu noble/main amd64 Packages\n        100 /var/lib/dpkg/status\nAnd indeed, there is an update available from that PPA, and the next time\nunattended-upgrade\nruns on its own, it will apply that update. In fact, if the\n--dry-run\noption is removed from the command-line we just ran, the update will be installed.", "meta": {"site": "documentation.ubuntu.com", "crawl_ts": "2025-11-27T10:38:30Z", "original_len_words": 3389}}
{"id": "015050465e", "source_url": "https://documentation.ubuntu.com/server/how-to/software/kernel-crash-dump/", "title": "Kernel crash dump - Ubuntu Server documentation", "text": "Kernel crash dump - Ubuntu Server documentation\nContents\nMenu\nExpand\nLight mode\nDark mode\nAuto light/dark, in light mode\nAuto light/dark, in dark mode\nSkip to content\nBack to top\nView this page\nKernel crash dump\n¶\nA ‘kernel crash dump’ refers to a portion of the contents of volatile memory (RAM) that is copied to disk whenever the execution of the kernel is disrupted. The following events can cause a kernel disruption:\nKernel panic\nNon-maskable interrupts (NMI)\nMachine check exceptions (MCE)\nHardware failure\nManual intervention\nFor some of these events (kernel panic, NMI) the kernel will react automatically and trigger the crash dump mechanism through\nkexec\n. In other situations a manual intervention is required in order to capture the memory. Whenever one of the above events occurs, it is important to find out the root cause in order to prevent it from happening again. The cause can be determined by inspecting the copied memory contents.\nKernel crash dump mechanism\n¶\nWhen a kernel panic occurs, the kernel relies on the\nkexec\nmechanism to quickly reboot a new instance of the kernel in a pre-reserved section of memory that had been allocated when the system booted (see below). This permits the existing memory area to remain untouched in order to safely copy its contents to storage.\nKDump enabled by default\n¶\nStarting in Oracular Oriole (24.10) the kernel crash dump facility will be enabled by default during standard Ubuntu Desktop or Ubuntu Server installations on systems that meet the following requirements:\nthe system has at least 4 CPU threads\nthe system has at least 6GB of RAM, and less than 2TB of RAM\nthe free space available in\n/var\nis more than 5 times the amount of RAM and swap space\nand the CPU architecture is\namd64 or s390x, or\narm64 and UEFI is used\nOn machines with it enabled (either by default or by manual installation), it can be disabled via the command:\nsudo\napt\nremove\nkdump-tools\nOn machines that do not meet these requirements and on pre-24.10 releases, the kernel crash dump facility can be enabled manually by following the installation instructions that follow.\nInstallation\n¶\nThe kernel crash dump utility is installed with the following command:\nsudo\napt\ninstall\nkdump-tools\nNote\nStarting with 16.04, the kernel crash dump mechanism is enabled by default.\nDuring the installation, you will be prompted with the following dialog:\n|------------------------| Configuring kdump-tools |------------------------|\n |                                                                           |\n |                                                                           |\n | If you choose this option, the kdump-tools mechanism will be enabled.  A  |\n | reboot is still required in order to enable the crashkernel kernel        |\n | parameter.                                                                |\n |                                                                           |\n | Should kdump-tools be enabled be default?                                 |\n |                                                                           |\n |                    <Yes>                       <No>                       |\n |                                                                           |\n |---------------------------------------------------------------------------|\n‘Yes’ should be selected to enable\nkdump-tools\n.  If you want to revisit your choice, you can use the\ndpkg-reconfigure\nkdump-tools\ncommand and answer ‘Yes’ or ‘No’.\nAs well, you will also need to edit\n/etc/default/kdump-tools\nto enable\nkdump\nby including the following line:\nUSE_KDUMP=1\nIf you’re disabling\nkdump-tools\n, either set USE_KDUMP=0 or remove the line from the file.\nIf a reboot has not been done since installation of the\nlinux-crashdump\npackage, a reboot will be required in order to activate the\ncrashkernel=\nboot\nparameter. Upon reboot,\nkdump-tools\nwill be enabled and active.\nIf you enable\nkdump-tools\nafter a reboot, you will only need to issue the\nkdump-config\nload\ncommand to activate the\nkdump\nmechanism.\nYou can view the current status of\nkdump\nvia the command\nkdump-config\nshow\n.  This will display something like this:\nDUMP_MODE:        kdump\nUSE_KDUMP:        1\nKDUMP_SYSCTL:     kernel.panic_on_oops=1\nKDUMP_COREDIR:    /var/crash\ncrashkernel addr: \n   /var/lib/kdump/vmlinuz\nkdump initrd: \n   /var/lib/kdump/initrd.img\ncurrent state:    ready to kdump\nkexec command:\n  /sbin/kexec -p --command-line=\"...\" --initrd=...\nThis tells us that we will find core dumps in\n/var/crash\n.\nConfiguration\n¶\nIn addition to local dump, it is now possible to use the remote dump functionality to send the kernel crash dump to a remote server, using either the SSH or NFS protocols.\nLocal kernel crash dumps\n¶\nLocal dumps are configured automatically and will remain in use unless a remote protocol is chosen. Many configuration options exist and are thoroughly documented in the\n/etc/default/kdump-tools\nfile.\nRemote kernel crash dumps using the SSH protocol\n¶\nTo enable remote dumps using the SSH protocol, the\n/etc/default/kdump-tools\nmust be modified in the following manner:\n# ---------------------------------------------------------------------------\n# Remote dump facilities:\n# SSH - username and hostname of the remote server that will receive the dump\n#       and dmesg files.\n# SSH_KEY - Full path of the ssh private key to be used to login to the remote\n#           server. use kdump-config propagate to send the public key to the\n#           remote server\n# HOSTTAG - Select if hostname of IP address will be used as a prefix to the\n#           timestamped directory when sending files to the remote server.\n#           'ip' is the default.\nSSH=\"ubuntu@kdump-netcrash\"\nThe only mandatory variable to define is SSH. It must contain the username and\nhostname\nof the remote server using the format\n{username}@{remote\nserver}\n.\nSSH_KEY\nmay be used to provide an existing private key to be used. Otherwise, the\nkdump-config\npropagate\ncommand will create a new keypair. The\nHOSTTAG\nvariable may be used to use the hostname of the system as a prefix to the remote directory to be created instead of the IP address.\nThe following example shows how\nkdump-config\npropagate\nis used to create and propagate a new keypair to the remote server:\nsudo\nkdump-config\npropagate\nWhich produces an output like this:\nNeed to generate a new ssh key...\nThe authenticity of host 'kdump-netcrash (192.168.1.74)' can't be established.\nECDSA key fingerprint is SHA256:iMp+5Y28qhbd+tevFCWrEXykDd4dI3yN4OVlu3CBBQ4.\nAre you sure you want to continue connecting (yes/no)? yes\nubuntu@kdump-netcrash's password: \npropagated ssh key /root/.ssh/kdump_id_rsa to server ubuntu@kdump-netcrash\nThe password of the account used on the remote server will be required in order to successfully send the public key to the server.\nThe\nkdump-config\nshow\ncommand can be used to confirm that\nkdump\nis correctly configured to use the SSH protocol:\nkdump-config\nshow\nWhose output appears like this:\nDUMP_MODE:        kdump\nUSE_KDUMP:        1\nKDUMP_SYSCTL:     kernel.panic_on_oops=1\nKDUMP_COREDIR:    /var/crash\ncrashkernel addr: 0x2c000000\n   /var/lib/kdump/vmlinuz: symbolic link to /boot/vmlinuz-4.4.0-10-generic\nkdump initrd: \n   /var/lib/kdump/initrd.img: symbolic link to /var/lib/kdump/initrd.img-4.4.0-10-generic\nSSH:              ubuntu@kdump-netcrash\nSSH_KEY:          /root/.ssh/kdump_id_rsa\nHOSTTAG:          ip\ncurrent state:    ready to kdump\nRemote kernel crash dumps using the NFS protocol\n¶\nTo enable remote dumps using the NFS protocol, the\n/etc/default/kdump-tools\nmust be modified in the following manner:\n# NFS -     Hostname and mount point of the NFS server configured to receive\n#           the crash dump. The syntax must be {HOSTNAME}:{MOUNTPOINT} \n#           (e.g. remote:/var/crash)\n#\nNFS=\"kdump-netcrash:/var/crash\"\nAs with the SSH protocol, the\nHOSTTAG\nvariable can be used to replace the IP address by the hostname as the prefix of the remote directory.\nThe\nkdump-config\nshow\ncommand can be used to confirm that\nkdump\nis correctly configured to use the NFS protocol :\nkdump-config\nshow\nWhich produces an output like this:\nDUMP_MODE:        kdump\nUSE_KDUMP:        1\nKDUMP_SYSCTL:     kernel.panic_on_oops=1\nKDUMP_COREDIR:    /var/crash\ncrashkernel addr: 0x2c000000\n   /var/lib/kdump/vmlinuz: symbolic link to /boot/vmlinuz-4.4.0-10-generic\nkdump initrd: \n   /var/lib/kdump/initrd.img: symbolic link to /var/lib/kdump/initrd.img-4.4.0-10-generic\nNFS:              kdump-netcrash:/var/crash\nHOSTTAG:          hostname\ncurrent state:    ready to kdump\nVerification\n¶\nTo confirm that the kernel dump mechanism is enabled, there are a few things to verify. First, confirm that the\ncrashkernel\nboot parameter is present (note that the following line has been split into two to fit the format of this document):\ncat\n/proc/cmdline\nBOOT_IMAGE\n=\n/vmlinuz-3.2.0-17-server\nroot\n=\n/dev/mapper/PreciseS-root\nro\ncrashkernel\n=\n384M-2G:64M,2G-:128M\nThe\ncrashkernel\nparameter has the following syntax:\ncrashkernel=<range1>:<size1>[,<range2>:<size2>,...][@offset]\n    range=start-[end] 'start' is inclusive and 'end' is exclusive.\nSo for the\ncrashkernel\nparameter found in\n/proc/cmdline\nwe would have :\ncrashkernel\n=\n384M-2G:64M,2G-:128M\nThe above value means:\nif the RAM is smaller than 384M, then don’t reserve anything (this is the “rescue” case)\nif the RAM size is between 386M and 2G (exclusive), then reserve 64M\nif the RAM size is larger than 2G, then reserve 128M\nSecond, verify that the kernel has reserved the requested memory area for the\nkdump\nkernel by running:\ndmesg\n|\ngrep\n-i\ncrash\nWhich produces the following output in this case:\n...\n[\n0\n.000000\n]\nReserving\n64MB\nof\nmemory\nat\n800MB\nfor\ncrashkernel\n(\nSystem\nRAM:\n1023MB\n)\nFinally, as seen previously, the\nkdump-config\nshow\ncommand displays the current status of the\nkdump-tools\nconfiguration :\nkdump-config\nshow\nWhich produces:\nDUMP_MODE:        kdump\nUSE_KDUMP:        1\nKDUMP_SYSCTL:     kernel.panic_on_oops=1\nKDUMP_COREDIR:    /var/crash\ncrashkernel addr: 0x2c000000\n   /var/lib/kdump/vmlinuz: symbolic link to /boot/vmlinuz-4.4.0-10-generic\nkdump initrd: \n      /var/lib/kdump/initrd.img: symbolic link to /var/lib/kdump/initrd.img-4.4.0-10-generic\ncurrent state:    ready to kdump\n\nkexec command:\n      /sbin/kexec -p --command-line=\"BOOT_IMAGE=/vmlinuz-4.4.0-10-generic root=/dev/mapper/VividS--vg-root ro debug break=init console=ttyS0,115200 irqpoll maxcpus=1 nousb systemd.unit=kdump-tools.service\" --initrd=/var/lib/kdump/initrd.img /var/lib/kdump/vmlinuz\nTesting the crash dump mechanism\n¶\nWarning\nTesting the crash dump mechanism\nwill cause a system reboot\n. In certain situations, this can cause data loss if the system is under heavy load. If you want to test the mechanism, make sure that the system is idle or under very light load.\nVerify that the\nSysRQ\nmechanism is enabled by looking at the value of the\n/proc/sys/kernel/sysrq\nkernel parameter:\ncat\n/proc/sys/kernel/sysrq\nIf a value of\n0\nis returned, the dump and then reboot feature is disabled. A value greater than\n1\nindicates that a sub-set of\nsysrq\nfeatures is enabled. See\n/etc/sysctl.d/10-magic-sysrq.conf\nfor a detailed description of the options and their default values. Enable dump then reboot testing with the following command:\nsudo\nsysctl\n-w\nkernel.sysrq\n=\n1\nOnce this is done, you must become root, as just using\nsudo\nwill not be sufficient. As the\nroot\nuser, you will have to issue the command\necho\nc\n>\n/proc/sysrq-trigger\n. If you are using a network connection, you will lose contact with the system. This is why it is better to do the test while being connected to the system console. This has the advantage of making the kernel dump process visible.\nA typical test output should look like the following :\nsudo -s\n[sudo] password for ubuntu: \n# echo c > /proc/sysrq-trigger\n[   31.659002] SysRq : Trigger a crash\n[   31.659749] BUG: unable to handle kernel NULL pointer dereference at           (null)\n[   31.662668] IP: [<ffffffff8139f166>] sysrq_handle_crash+0x16/0x20\n[   31.662668] PGD 3bfb9067 PUD 368a7067 PMD 0 \n[   31.662668] Oops: 0002 [#1] SMP \n[   31.662668] CPU 1 \n....\nThe rest of the output is truncated, but you should see the system rebooting and somewhere in the log, you will see the following line :\nBegin: Saving vmcore from kernel crash ...\nOnce completed, the system will reboot to its normal operational mode. You will then find the kernel crash dump file, and related subdirectories, in the\n/var/crash\ndirectory by running, e.g.\nls\n/var/crash\n, which produces the following:\n201809240744\nkexec_cmd\nlinux-image-4.15.0-34-generic-201809240744.crash\nIf the dump does not work due to an ‘out of memory’ (OOM) error, then try increasing the amount of reserved memory by editing\n/etc/default/grub.d/kdump-tools.cfg\n. For example, to reserve 512 megabytes:\nGRUB_CMDLINE_LINUX_DEFAULT=\"$GRUB_CMDLINE_LINUX_DEFAULT crashkernel=384M-:512M\"\nYou can then run\nsudo\nupdate-grub\n, reboot afterwards, and then test again.\nResources\n¶\nKernel crash dump is a vast topic that requires good knowledge of the Linux kernel. You can find more information on the topic here:\nKdump kernel documentation\n.\nAnalyzing Linux Kernel Crash\n(Based on Fedora, it still gives a good walkthrough of kernel dump analysis)", "meta": {"site": "documentation.ubuntu.com", "crawl_ts": "2025-11-27T10:38:30Z", "original_len_words": 1858}}
{"id": "6d0c8ed6eb", "source_url": "https://documentation.ubuntu.com/server/how-to/software/package-management/", "title": "Install and manage packages - Ubuntu Server documentation", "text": "Install and manage packages - Ubuntu Server documentation\nContents\nMenu\nExpand\nLight mode\nDark mode\nAuto light/dark, in light mode\nAuto light/dark, in dark mode\nSkip to content\nBack to top\nView this page\nInstall and manage packages\n¶\nThe recommended way to install Debian packages (“deb” files) is using the\nAdvanced Packaging Tool (APT), which can be used on the command line using the\napt\nutility.\nThe commands contained within\napt\nprovide the means to install new software\npackages, upgrade existing software packages, update the package list index,\nand even upgrade the entire Ubuntu system.\nUpdate the package index\n¶\nThe APT package index is a database of available packages from the\nrepositories defined in the\n/etc/apt/sources.list\nfile and in the\n/etc/apt/sources.list.d\ndirectory. To update the local package index with\nthe latest changes made in the repositories, and thereby access the most\nup-to-date version of the package you’re interested in, type the following:\nsudo\napt\nupdate\nInstall a package\n¶\nAs an example, to install the\nnmap\nnetwork scanner, run the following command:\nsudo\napt\ninstall\nnmap\nTip\nYou can install or remove multiple packages at once by separating them with\nspaces.\nRemove a package\n¶\nTo remove the package installed in the previous example, run the following:\nsudo\napt\nremove\nnmap\nAdding the\n--purge\noption to\napt\nremove\nwill remove the package\nconfiguration files as well. This may or may not be what you want, so use it\nwith caution.\nNote\nWhile\napt\nis a command-line tool, it is intended to be used interactively,\nand not to be called from non-interactive scripts. The\napt-get\ncommand should\nbe used in scripts (perhaps with the\n--quiet\nflag). For basic commands the\nsyntax of the two tools is identical.\nUpgrading packages\n¶\nInstalled packages on your computer may periodically have upgrades available from the package repositories (e.g., security updates). To upgrade your system, first update your package index and then perform the upgrade – as follows:\nsudo\napt\nupdate\nsudo\napt\nupgrade\nFor details on how to upgrade to a new Ubuntu release, see our\nguide on upgrading releases\n. For further information about using APT, read the comprehensive\nAPT User’s Guide\n, or type\napt\nhelp\n.\nAptitude\n¶\nLaunching Aptitude with no command-line options will give you a menu-driven, text-based\nfrontend\nto the APT system. Many of the common package management functions, such as installation, removal, and upgrade, can be performed in Aptitude with single-key commands, which are typically lowercase letters.\nAptitude is best suited for use in a non-graphical terminal environment to ensure the command keys work properly. You can start the menu-driven interface of Aptitude as a regular user by typing the following command at a terminal prompt:\nsudo\naptitude\nWhen Aptitude starts, you will see a menu bar at the top of the screen and two panes below the menu bar. The top pane contains package categories, such as “New Packages” and “Not Installed Packages”. The bottom pane contains information related to the packages and package categories.\nUsing Aptitude for package management is relatively straightforward thanks to its user interface. The following are examples of common package management functions as performed in Aptitude:\nInstalling packages\n¶\nTo install a package, locate it in the “Not Installed Packages” category by using the keyboard arrow keys and the\nEnter\nkey.\nHighlight the desired package, then press the\n+\nkey. The package entry should turn\ngreen\n, which indicates it has been marked for installation. Now press\ng\nto be presented with a summary of package actions. Press\ng\nagain, and the package will be downloaded and installed. When finished, press\nEnter\nto return to the menu.\nRemove Packages\n¶\nTo remove a package, locate it in the “Installed Packages” category by using the keyboard arrow keys and the\nEnter\nkey.\nHighlight the package you want to remove, then press the\n-\nkey. The package entry should turn\npink\n, indicating it has been marked for removal. Now press\ng\nto be presented with a summary of package actions. Press\ng\nagain, and the package will be removed. When finished, press\nEnter\nto return to the menu.\nUpdating the package index\n¶\nTo update the package index, press the\nu\nkey.\nUpgrade packages\n¶\nTo upgrade packages, first update the package index as detailed above, and then press the\nU\nkey to mark all packages with available updates. Now press\ng\n, which will present you with a summary of package actions. Press\ng\nagain to begin the download and installation. When finished, press\nEnter\nto return to the menu.\nThe first column of information displayed in the package list (in the top pane) lists the current state of the package (when viewing packages). It uses the following key to describe the package state:\ni\n: Installed package\nc\n: Package not installed, but package configuration remains on the system\np\n: Purged from system\nv\n: Virtual package\nB\n: Broken package\nu\n: Unpacked files, but package not yet configured\nC\n: Half-configured - configuration failed and requires fix\nH\n: Half-installed - removal failed and requires a fix\nTo exit Aptitude, simply press the\nq\nkey and confirm you want to exit. Many other functions are available from the Aptitude menu by pressing the\nF10\nkey.\nCommand-line Aptitude\n¶\nYou can also use Aptitude as a command-line tool, similar to\napt\n. To install the\nnmap\npackage with all necessary dependencies (as in the\napt\nexample), you would use the following command:\nsudo\naptitude\ninstall\nnmap\nTo remove the same package, you would use the command:\nsudo\naptitude\nremove\nnmap\nConsult the\nAptitude manpages\nfor full details of Aptitude’s command-line options.\ndpkg\n¶\ndpkg\nis a package manager for Debian-based systems. It can install, remove, and build packages, but unlike other package management systems, it cannot automatically download and install packages – or their dependencies.\nAPT and Aptitude are newer, and layer additional features on top of\ndpkg\n. This section covers using\ndpkg\nto manage locally installed packages.\nList packages\n¶\nTo list\nall\npackages in the system’s package database (both installed and uninstalled) run the following command from a terminal prompt:\ndpkg\n-l\nDepending on the number of packages on your system, this can generate a large amount of output. Pipe the output through\ngrep\nto see if a specific package is installed:\ndpkg\n-l\n|\ngrep\napache2\nReplace\napache2\nwith any package name, part of a package name, or a regular expression.\nList files\n¶\nTo list the files installed by a package, in this case the\nufw\npackage, enter:\ndpkg\n-L\nufw\nIf you are unsure which package installed a file,\ndpkg\n-S\nmay be able to tell you. For example:\ndpkg\n-S\n/etc/host.conf\nbase-files:\n/etc/host.conf\nThe output shows that the\n/etc/host.conf\nbelongs to the base-files package.\nNote\nMany files are automatically generated during the package install process, and even though they are on the\nfilesystem\n,\ndpkg\n-S\nmay not know which package they belong to.\nInstalling a deb file\n¶\nYou can install a local\n.deb\nfile by entering:\nsudo\ndpkg\n-i\nzip_3.0-4_amd64.deb\nChange\nzip_3.0-4_amd64.deb\nto the actual file name of the local\n.deb\nfile you wish to install.\nUninstalling packages\n¶\nYou can uninstall a package by running:\nsudo\ndpkg\n-r\nzip\nCaution\nUninstalling packages using\ndpkg\n, is\nNOT\nrecommended in most cases. It is better to use a package manager that handles dependencies to ensure that the system is left in a consistent state. For example, using\ndpkg\n-r\nzip\nwill remove the\nzip\npackage, but any packages that depend on it will still be installed and may no longer function correctly as a result.\nFor more\ndpkg\noptions see the\ndpkg(1)\nmanpage:\nman\ndpkg\n.\nAPT configuration\n¶\nConfiguration of the APT system repositories is stored in the\n/etc/apt/sources.list\nfile and the\n/etc/apt/sources.list.d\ndirectory. An example of this file is referenced here, along with information on adding or removing repository references from the file.\nYou can edit the file to enable and disable repositories. For example, to disable the requirement to insert the Ubuntu CD-ROM whenever package operations occur, simply comment out the appropriate line for the CD-ROM, which appears at the top of the file:\n# no more prompting for CD-ROM please\n# deb cdrom:[DISTRO-APT-CD-NAME - Release i386 (20111013.1)]/ DISTRO-SHORT-CODENAME main restricted\nAutomatic updates\n¶\nIt’s possible to setup an Ubuntu system with Automatic Updates, such that certain types of upgrades are applied automatically. In fact, the default for Ubuntu Server is to automatically apply security updates. Please see the\nAutomatic updates\nsection for details.\nExtra repositories\n¶\nIn addition to the officially-supported package repositories available for Ubuntu, there are also community-maintained repositories which add thousands more packages for potential installation. Two of the most popular are the\nUniverse\nand\nMultiverse\nrepositories. These repositories are not officially supported by Ubuntu, but because they are maintained by the community they generally provide packages which are safe for use with your Ubuntu computer.\nFor more information, see our guide on\nusing third-party repositories\n.\nWarning\nBe advised that packages in Universe and Multiverse are not officially supported and do not receive security patches, except through Ubuntu Pro’s\nExpanded Security Maintenance\n. A subscription to\nUbuntu Pro\nis free for personal use on up to five machines.\nPackages in the\nmultiverse\nrepository often have licensing issues that prevent them from being distributed with a free operating system, and they may be illegal in your locality.\nMany other package sources are available – sometimes even offering only one package, as in the case of packages provided by the developer of a single application. You should always be cautious when using non-standard package sources/repos, however. Research the packages and their origins carefully before performing any installation, as some packages could render your system unstable or non-functional in some respects.\nBy default, the\nuniverse\nand\nmultiverse\nrepositories are enabled. If you would like to disable them, edit\n/etc/apt/sources.list\nand comment out the following lines:\ndeb http://archive.ubuntu.com/ubuntu DISTRO-SHORT-CODENAME universe multiverse\ndeb-src http://archive.ubuntu.com/ubuntu DISTRO-SHORT-CODENAME universe multiverse\n    \ndeb http://us.archive.ubuntu.com/ubuntu/ DISTRO-SHORT-CODENAME universe\ndeb-src http://us.archive.ubuntu.com/ubuntu/ DISTRO-SHORT-CODENAME universe\ndeb http://us.archive.ubuntu.com/ubuntu/ DISTRO-SHORT-CODENAME-updates universe\ndeb-src http://us.archive.ubuntu.com/ubuntu/ DISTRO-SHORT-CODENAME-updates universe\n    \ndeb http://us.archive.ubuntu.com/ubuntu/ DISTRO-SHORT-CODENAME multiverse\ndeb-src http://us.archive.ubuntu.com/ubuntu/ DISTRO-SHORT-CODENAME multiverse\ndeb http://us.archive.ubuntu.com/ubuntu/ DISTRO-SHORT-CODENAME-updates multiverse\ndeb-src http://us.archive.ubuntu.com/ubuntu/ DISTRO-SHORT-CODENAME-updates multiverse\n    \ndeb http://security.ubuntu.com/ubuntu DISTRO-SHORT-CODENAME-security universe\ndeb-src http://security.ubuntu.com/ubuntu DISTRO-SHORT-CODENAME-security universe\ndeb http://security.ubuntu.com/ubuntu DISTRO-SHORT-CODENAME-security multiverse\ndeb-src http://security.ubuntu.com/ubuntu DISTRO-SHORT-CODENAME-security multiverse\nlogging\n¶\nActions of the\napt\ncommand, such as installation and removal of packages,\nare logged in the\n/var/log/dpkg.log\nlog file.\nFurther reading\n¶\nMost of the material covered in this chapter is available in the respective man pages, many of which are available online.\nThe\nInstalling Software\nUbuntu wiki page has more information.\nThe\nAPT User’s Guide\ncontains useful information regarding APT usage.\nFor more information about systemd timer units (and systemd in general), visit the\nsystemd(1)\nmanual page and\nsystemd.timer(5)\nmanual page\nSee the\nAptitude user’s manual\nfor more Aptitude options.\nThe\nAdding Repositories HOWTO (Ubuntu Wiki)\npage contains more details on adding repositories.", "meta": {"site": "documentation.ubuntu.com", "crawl_ts": "2025-11-27T10:38:30Z", "original_len_words": 1827}}
{"id": "43a24805d1", "source_url": "https://documentation.ubuntu.com/server/how-to/software/report-a-bug/", "title": "How to report a bug in Ubuntu Server - Ubuntu Server documentation", "text": "How to report a bug in Ubuntu Server - Ubuntu Server documentation\nContents\nMenu\nExpand\nLight mode\nDark mode\nAuto light/dark, in light mode\nAuto light/dark, in dark mode\nSkip to content\nBack to top\nView this page\nHow to report a bug in Ubuntu Server\n¶\nThe Ubuntu project, including Ubuntu Server,\nuses Launchpad\nas its bug tracker. To file a bug, you will first need to\ncreate a Launchpad account\n.\nReport bugs with\napport-cli\n¶\nThe preferred way to report a bug is with the\napport-cli\ncommand. This command collects information from the machine on which it is run and publishes it to the bug report on Launchpad.\nGetting this information to Launchpad can be a challenge if the system is not running a desktop environment with a browser (a common scenario with servers) or if it does not have Internet access. The steps to take in these situations are described below.\nNote\nThe commands\napport-cli\nand\nubuntu-bug\nshould give the same results on a command-line interface (CLI) server. The latter is actually a symlink to\napport-bug\n, which is intelligent enough to know whether a desktop environment is in use, and will choose\napport-cli\nif not. Since server systems tend to be CLI-only,\napport-cli\nwas chosen from the outset in this guide.\nBug reports in Ubuntu need to be filed against a specific software package, so the name of the package (source package or program name/path) affected by the bug needs to be supplied to\napport-cli\n:\napport-cli\nPACKAGENAME\nOnce\napport-cli\nhas finished gathering information you will be asked what to do with it. For instance, to report a bug against vim using\napport-cli\nvim\nproduces output like this:\n*** Collecting problem information\n    \nThe collected information can be sent to the developers to improve the\napplication. This might take a few minutes.\n...\n    \n*** Send problem report to the developers?\n    \nAfter the problem report has been sent, please fill out the form in the\nautomatically opened web browser.\n   \nWhat would you like to do? Your options are:\n  S: Send report (2.8 KB)\n  V: View report\n  K: Keep report file for sending later or copying to somewhere else\n  I: Cancel and ignore future crashes of this program version\n  C: Cancel\nPlease choose (S/V/K/I/C):\nThe first three options are described below.\nS: Send report\n¶\nSubmits the collected information to Launchpad as part of the process of filing a new bug report. You will be given the opportunity to describe the bug in your own words.\n*** Uploading problem information\n    \nThe collected information is being sent to the bug tracking system.\nThis might take a few minutes.\n94%\n    \n*** To continue, you must visit the following URL:\n    \n  https://bugs.launchpad.net/ubuntu/+source/vim/+filebug/09b2495a-e2ab-11e3-879b-68b5996a96c8?\n    \nYou can launch a browser now, or copy this URL into a browser on another computer.\n    \n    \nChoices:\n  1: Launch a browser now\n  C: Cancel\nPlease choose (1/C):  1\nThe browser that will be used when choosing ‘1’ will be the one known on the system as\nwww-browser\nvia the\nDebian alternatives system\n. Examples of text-based browsers to install include links,\nELinks\n, lynx, and w3m. You can also manually point an existing browser at the given URL.\nV: View\n¶\nThis displays the collected information on the screen for review. This can be a lot of information! Press\nEnter\nto scroll through the screens. Press\nq\nto quit and return to the choice menu.\nK: Keep\n¶\nThis writes the collected information to disk. The resulting file can be later used to file the bug report, typically after transferring it to another Ubuntu system.\nWhat would you like to do? Your options are:\n  S: Send report (2.8 KB)\n  V: View report\n  K: Keep report file for sending later or copying to somewhere else\n  I: Cancel and ignore future crashes of this program version\n  C: Cancel\nPlease choose (S/V/K/I/C): k\nProblem report file: /tmp/apport.vim.1pg92p02.apport\nTo report the bug, get the file onto an Internet-enabled Ubuntu system and apply\napport-cli\nto it. This will cause the menu to appear immediately (since the information is already collected). You should then press\ns\nto send:\napport-cli\napport.vim.1pg92p02.apport\nTo directly save a report to disk (without menus) you can run:\napport-cli\nvim\n--save\napport.vim.test.apport\nReport names should end in\n.apport\n.\nNote\nIf this Internet-enabled system is non-Ubuntu/Debian,\napport-cli\nis not available so the bug will need to be created manually. An\napport\nreport is also not to be included as an attachment to a bug either so it is completely useless in this scenario.\nReporting application crashes\n¶\nThe software package that provides the\napport-cli\nutility,\napport\n, can be configured to automatically capture the state of a crashed application. This is enabled by default in\n/etc/default/apport\n.\nAfter an application crashes, if enabled,\napport\nwill store a crash report under\n/var/crash\n:\n-rw-r----- 1 peter    whoopsie 150K Jul 24 16:17 _usr_lib_x86_64-linux-gnu_libmenu-cache2_libexec_menu-cached.1000.crash\nUse the\napport-cli\ncommand with no arguments to process any pending crash reports. It will offer to report them one by one, as in the following example:\napport-cli\n*** Send problem report to the developers?\n    \nAfter the problem report has been sent, please fill out the form in the\nautomatically opened web browser.\n    \nWhat would you like to do? Your options are:\n  S: Send report (153.0 KB)\n  V: View report\n  K: Keep report file for sending later or copying to somewhere else\n  I: Cancel and ignore future crashes of this program version\n  C: Cancel\nPlease choose (S/V/K/I/C): s\nIf you send the report, as was done above, the prompt will be returned immediately and the\n/var/crash\ndirectory will then contain 2 extra files:\n-rw-r----- 1 peter    whoopsie 150K Jul 24 16:17 _usr_lib_x86_64-linux-gnu_libmenu-cache2_libexec_menu-cached.1000.crash\n-rw-rw-r-- 1 peter    whoopsie    0 Jul 24 16:37 _usr_lib_x86_64-linux-gnu_libmenu-cache2_libexec_menu-cached.1000.upload\n-rw------- 1 whoopsie whoopsie    0 Jul 24 16:37 _usr_lib_x86_64-linux-gnu_libmenu-cache2_libexec_menu-cached.1000.uploaded\nSending in a crash report like this will not immediately result in the creation of a new public bug. The report will be made private on Launchpad, meaning that it will be visible to only a limited set of bug triagers. These triagers will then scan the report for possible private data before creating a public bug.\nFurther reading\n¶\nSee the\nReporting Bugs\nUbuntu wiki page.\nAlso,\nthe Apport page\nhas some useful information. Though some of it pertains to using a\nGUI\n.", "meta": {"site": "documentation.ubuntu.com", "crawl_ts": "2025-11-27T10:38:30Z", "original_len_words": 1044}}
{"id": "dbf9b2ea74", "source_url": "https://documentation.ubuntu.com/server/how-to/software/snapshot-service/", "title": "How to use the Ubuntu snapshot service - Ubuntu Server documentation", "text": "How to use the Ubuntu snapshot service - Ubuntu Server documentation\nContents\nMenu\nExpand\nLight mode\nDark mode\nAuto light/dark, in light mode\nAuto light/dark, in dark mode\nSkip to content\nBack to top\nView this page\nHow to use the Ubuntu snapshot service\n¶\nThe Ubuntu snapshot service allows you to access old packages in the Ubuntu\narchive based on past dates. Some of the use cases for this service include:\nInstalling a superseded version of a package as it existed at a particular\ndate and time, which is useful to troubleshoot bugs or regressions, or to\nallow reproducibility.\nSetting upgrades to known states, which can be useful to ensure homogeneity\nfor a fleet of Ubuntu installations and to ensure predictability upon package\nupgrades (including unattended upgrades).\nSupport a structured update workflow by validating snapshots in different\nenvironments or by rolling out package upgrades in stages for a large set of\nmachines.\nHere we show how to set up and use the snapshot service.\nPrerequisites\n¶\nSnapshots are supported in Ubuntu 23.10 onwards and on updated installations of\nUbuntu 20.04 LTS (starting from\napt\n2.0.10) and Ubuntu 22.04 LTS (starting\nfrom\napt\n2.4.11).\nIn Ubuntu 24.04 LTS and later,\napt\nwill automatically detect whether a\nrepository supports snapshots. Therefore, there is no need for additional\nconfiguration before you can start using the Ubuntu snapshot service. For\nUbuntu versions lower than 24.04, you need to set a\nsnapshot\noption in the\nrelevant entries of the\n/etc/apt/sources.list\nfile. For instance:\nIf you have the following contents in the\n/etc/apt/sources.list\nfile\ndeb\nhttp\n:\n//\narchive\n.\nubuntu\n.\ncom\n/\nubuntu\njammy\nmain\nuniverse\nrestricted\nmultiverse\ndeb\nhttp\n:\n//\narchive\n.\nubuntu\n.\ncom\n/\nubuntu\njammy\n-\nupdates\nmain\nuniverse\nrestricted\nmultiverse\ndeb\nhttp\n:\n//\narchive\n.\nubuntu\n.\ncom\n/\nubuntu\njammy\n-\nbackports\nmain\nrestricted\nuniverse\nmultiverse\ndeb\nhttp\n:\n//\nsecurity\n.\nubuntu\n.\ncom\n/\nubuntu\njammy\n-\nsecurity\nmain\nrestricted\nuniverse\nmultiverse\nyou can enable the snapshot service for\nall components in all\npockets\nby changing it to\ndeb\n[\nsnapshot\n=\nyes\n]\nhttp\n:\n//\narchive\n.\nubuntu\n.\ncom\n/\nubuntu\njammy\nmain\nuniverse\nrestricted\nmultiverse\ndeb\n[\nsnapshot\n=\nyes\n]\nhttp\n:\n//\narchive\n.\nubuntu\n.\ncom\n/\nubuntu\njammy\n-\nupdates\nmain\nuniverse\nrestricted\nmultiverse\ndeb\n[\nsnapshot\n=\nyes\n]\nhttp\n:\n//\narchive\n.\nubuntu\n.\ncom\n/\nubuntu\njammy\n-\nbackports\nmain\nrestricted\nuniverse\nmultiverse\ndeb\n[\nsnapshot\n=\nyes\n]\nhttp\n:\n//\nsecurity\n.\nubuntu\n.\ncom\n/\nubuntu\njammy\n-\nsecurity\nmain\nrestricted\nuniverse\nmultiverse\nWithout the setup shown above,\napt\nwill simply ignore snapshot related\ncommand line options in Ubuntu releases lower than 24.04.\nThe following table describes whether the snapshot service can be used with\neach supported Ubuntu release, and whether or not it is necessary to configure\nthe\nsnapshot\noption in the\nsources.list\nfile.\nUbuntu Release\nSupports Snapshot Service?\nNeed to configure\nsources.list\n?\nNext Ubuntu releases\nYes\nNo\nUbuntu 25.10\nYes\nNo\nUbuntu 25.04\nYes\nNo\nUbuntu 24.04 LTS\nYes\nNo\nUbuntu 22.04 LTS\nYes (with\napt\n>=\n2.4.11\n)\nYes\nUbuntu 20.04 LTS\nYes (with\napt\n>=\n2.0.10\n)\nYes\nQuick start\n¶\nYou can start using the snapshot service right away by passing the\n--snapshot\noption to\napt\nfollowed by a timestamp in the format shown below.\n$ sudo apt install hello --update --snapshot 20240301T030400Z\nThe\n--snapshot\noption and the the timestamp format are discussed with more\ndetails in the next sections.\nUsing the snapshot service\n¶\nThere are several options when it comes to setting up Ubuntu snapshot services.\nHere we present the most relevant, supported ones.\nBelow, we refer to the snapshot ID as\n$SNAPSHOT_ID\n. This is a UTC date and\ntime formatted as YYYYMMDDTHHMMSSZ, e.g., 20240430T214500Z, which refers to the\nsnapshot that represents the state of the Ubuntu archive on April 30th, 2024,\nat 21:45:00 UTC.\nCurrently, the Ubuntu snapshot service provides snapshots for any date and time\nafter 1 March 2023\n.\nThe\n--snapshot\nCLI option\n¶\nThe snapshot service can be used through the\n--snapshot\n(or\n-S\n) CLI option\nfor\napt\n, which receives a snapshot ID argument.\n$ sudo apt update --snapshot $SNAPSHOT_ID\n$ sudo apt install $PACKAGE_NAME --snapshot $SNAPSHOT_ID\nYou can also use the short, atomic version to merge the two actions above in a\nsingle command, which will download the package information from the\nrepository, then download and install the package:\n$ sudo apt install $PACKAGE_NAME --update --snapshot $SNAPSHOT_ID\nor using the short version of the snapshot option:\n$ sudo apt install $PACKAGE_NAME --update -S $SNAPSHOT_ID\nFor instance, if you want to install Docker as it was released when Ubuntu\n24.04 LTS first came out, you could try a snapshot from May 2025:\n$ sudo apt update --snapshot 20240501T120000Z\nNote that you will need to keep using the snapshot option to let\napt\noperate\nover the snapshot repositories. For example, if you want to check what versions\nof Docker are available with the snapshot:\n$ apt policy docker.io --snapshot 20240501T120000Z\ndocker.io:\n  Installed: (none)\n  Candidate: 24.0.7-0ubuntu4\n  Version table:\n     24.0.7-0ubuntu4 500\n        500 https://snapshot.ubuntu.com/ubuntu/20240501T120000Z noble/universe amd64 Packages\nIf you forget to use the snapshot option,\napt\nwill operate over the regular archive:\n$ apt policy docker.io\ndocker.io:\n  Installed: (none)\n  Candidate: 28.2.2-0ubuntu1~24.04.1\n  Version table:\n     28.2.2-0ubuntu1~24.04.1 500\n        500 http://archive.ubuntu.com/ubuntu noble-updates/universe amd64 Packages\n     27.5.1-0ubuntu3~24.04.2 500\n        500 http://security.ubuntu.com/ubuntu noble-security/universe amd64 Packages\n     24.0.7-0ubuntu4 500\n        500 http://archive.ubuntu.com/ubuntu noble/universe amd64 Packages\nThen, you can install Docker from that snapshot:\n$ sudo apt install docker.io --snapshot 20240501T120000Z\n...\n$ docker --version\nDocker version 24.0.7, build 24.0.7-0ubuntu4\nNow, let’s say you checked the\nDocker package publishing history in\nLaunchpad\nand (for some reason) decided you want to install version\n26.1.3-0ubuntu1~24.04.1\n, which, as inferred from the publishing history,\nsuperseded\ndocker.io\n24.0.7-0ubuntu4.1\nin\nnoble-updates\non\n2024-11-25\n.\nThen,\n24.0.7-0ubuntu4.1\nwas removed from the\n-updates\npocket on\n2024-11-26\n.\nYou could then use\n20241126T230000Z\nas the snapshot ID to get the target\npackage (\n26.1.3-0ubuntu1~24.04.1\n):\n$ sudo apt install docker.io --update --snapshot 20241126T230000Z\n...\n$ docker --version\nDocker version 26.1.3, build 26.1.3-0ubuntu1~24.04.1\nNote\nNote that, at the time of writing, the version of\ndocker.io\nin the\nnoble-security\npocket is\n27.5.1-0ubuntu3~24.04.2\n, i.e., the version used in\nthe example above may be affected by known vulnerabilities. When using the\nsnapshot service, do make sure to check the latest version available in your\nUbuntu release’s\n-security\npocket to make sure you are not installing a vulnerable\npackage.\nConfiguring the snapshot service for specific repositories\n¶\nIn your\napt\nrepositories configuration files, it is possible to specify\nsnapshots to be used for each specific repository.\nFor Ubuntu 24.04 LTS and later, which uses the deb822 style by default, we add\na\nSnapshot\noption to the relevant sources file in the following format:\nSnapshot: $SNAPSHOT_ID\nFor Ubuntu series lower than 24.04, you change the value of the\nsnapshot\noption in your sources file, i.e., if you had the following entry in your\n/etc/apt/sources.list\nfile\ndeb\n[\nsnapshot\n=\nyes\n]\nhttp\n:\n//\narchive\n.\nubuntu\n.\ncom\n/\nubuntu\n...\nyou replace the\nyes\nvalue with the snapshot ID:\ndeb [snapshot=$SNAPSHOT_ID] http://archive.ubuntu.com/ubuntu ...\nLet’s say you want to pin a specific snapshot for all the pockets in your Ubuntu\n24.04 LTS server. Then, you add the\nSnapshot\noptions to\n/etc/apt/sources.list.d/ubuntu.sources\n:\nTypes\n:\ndeb\nURIs\n:\nhttp\n:\n//\narchive\n.\nubuntu\n.\ncom\n/\nubuntu\nSuites\n:\nnoble\nnoble\n-\nupdates\nnoble\n-\nbackports\nComponents\n:\nmain\nuniverse\nrestricted\nmultiverse\nSigned\n-\nBy\n:\n/\nusr\n/\nshare\n/\nkeyrings\n/\nubuntu\n-\narchive\n-\nkeyring\n.\ngpg\nSnapshot\n:\n20250530\nT223000Z\nTypes\n:\ndeb\nURIs\n:\nhttp\n:\n//\nsecurity\n.\nubuntu\n.\ncom\n/\nubuntu\nSuites\n:\nnoble\n-\nsecurity\nComponents\n:\nmain\nuniverse\nrestricted\nmultiverse\nSigned\n-\nBy\n:\n/\nusr\n/\nshare\n/\nkeyrings\n/\nubuntu\n-\narchive\n-\nkeyring\n.\ngpg\nSnapshot\n:\n20250530\nT223000Z\nAfterwards, you can run the following commands to install the Docker version\npresent in that snapshot:\n$ sudo apt install --update docker.io\nto install the Docker version present in that snapshot.\n$ docker --version\nDocker version 27.5.1, build 27.5.1-0ubuntu3~24.04.1\nNote that, when you configure a repository to use a snapshot using the method\ndescribed above,\napt\nwill always ignore the\n--snapshot\noption:\n$ sudo apt install --update docker.io --snapshot 20251013T2300Z\n...\nHit:5 https://snapshot.ubuntu.com/ubuntu/20250530T223000Z noble InRelease\nHit:6 https://snapshot.ubuntu.com/ubuntu/20250530T223000Z noble-updates InRelease\nHit:7 https://snapshot.ubuntu.com/ubuntu/20250530T223000Z noble-backports InRelease\nHit:8 https://snapshot.ubuntu.com/ubuntu/20250530T223000Z noble-security InRelease\n...\ndocker.io is already the newest version (27.5.1-0ubuntu3~24.04.1).\n0 upgraded, 0 newly installed, 0 to remove and 3 not upgraded.\nAs you can see from the logs above,\napt\nis still using the snapshot\nconfigured in\n/etc/apt/sources.list.d/ubuntu.sources\n, ignoring the\n--snapshot\nCLI option.\nConfiguring the snapshot service globally\n¶\nAs an alternative to configuring a specific snapshot for each individual\nrepository, as described in the previous section, you can configure a snapshot\nglobally for all repositories that have snapshots enabled.\nWarning\nIf you are following these examples until here, make sure to revert the changes\nto the sources configuration file made in the previous section.\nLet’s configure\napt\nto default to a specific snapshot by setting the\nAPT::Snapshot\noption:\n$ echo 'APT::Snapshot \"20250801T111111Z\";' | sudo tee /etc/apt/apt.conf.d/50snapshot\nThe system will now default to fetching packages from the configured snapshot:\n$ sudo apt install docker.io --update\n...\n$ docker --version\nDocker version 27.5.1, build 27.5.1-0ubuntu3~24.04.2\nNote that, in contrast to repositories with snapshots configured in the\nsources file as shown in the previous section, configuring a snapshot globally\nwill not make\napt\nignore the\n--snapshot\nCLI option:\n$ sudo apt install docker.io --update --snapshot 20251013T120000Z\n$ docker --version\nDocker version 28.2.2, build 28.2.2-0ubuntu1~24.04.1\nYou can revert the global configuration by removing the file which added it:\n$ sudo rm /etc/apt/apt.conf.d/50snapshot\nFurther reading\n¶\nThe Ubuntu snapshot service official page and documentation\nSecuring multiple Ubuntu instances while maximising uptime\nIntegrating the Ubuntu Snapshot Service into systems management and update tools", "meta": {"site": "documentation.ubuntu.com", "crawl_ts": "2025-11-27T10:38:31Z", "original_len_words": 1656}}
{"id": "b7cd44b6a0", "source_url": "https://documentation.ubuntu.com/server/how-to/software/upgrade-your-release/", "title": "How to upgrade your Ubuntu release - Ubuntu Server documentation", "text": "How to upgrade your Ubuntu release - Ubuntu Server documentation\nContents\nMenu\nExpand\nLight mode\nDark mode\nAuto light/dark, in light mode\nAuto light/dark, in dark mode\nSkip to content\nBack to top\nView this page\nHow to upgrade your Ubuntu release\n¶\nIn this page we show how to upgrade an Ubuntu Server or Ubuntu cloud image to the next major release. This is different from your regular software updates.\nWe recommend running a Long Term Support (LTS) release as it provides 5 years of standard support and security updates, whereas interim releases are only supported for nine months.\nAfter the initial standard support period ends for an LTS release, an extended maintenance period is available via an\nUbuntu Pro subscription\n, which provides coverage for an additional five years and is available for free on up to five machines. Find out more about the\nrelease lifecycle and support period\nfor your release.\nUnderstanding Upgrade Paths\n¶\nYou can only upgrade from one LTS release directly to the\nnext sequential LTS release\n. For example, if you are on Ubuntu 16.04 LTS, you can upgrade to Ubuntu 18.04 LTS.\nHowever, you cannot skip releases (e.g. jump from 16.04 LTS to 20.04 LTS).If you need to reach a later LTS, you will have to upgrade in stages: first to Ubuntu 18.04 LTS, then to Ubuntu 20.04 LTS, and so on.\nPre-upgrade checklist\n¶\nBefore starting a major release upgrade, it’s important to prepare your system to ensure a smooth transition. This step is essential, so we need to review the following items:\nReview Releases notes:\nAlways check the\nrelease notes\nfor the new Ubuntu version we are moving to. This can be found on the\nUbuntu Wiki Releases Page\n.\nFully update the current system:\nThe release upgrade process requires that the current system has all the latest updates installed. This is a standard\npackage upgrade\n:\napt update\nwill refresh package index database, and\napt upgrade\nwill download and install the latest versions of installed packages.\nRun these commands to ensure everything is up to date:\nsudo\napt\nupdate\nsudo\napt\nupgrade\nConfirm both commands complete successfully and no further updates are available.\nAfter applying all updates, it may be necessary to\nreboot your system.\nThe release upgrade process will let you know if that’s needed, but you can also check manually before: if the file\n/run/reboot-required\nexists, then you will need to reboot.\nCheck that there is enough free space:\nA release upgrade involves downloading hundreds of new packages, which can be several gigabytes. Make sure you have enough free disk space.\nDedicate time for the upgrade:\nThis is an interactive process. The release upgrade will sometimes stop and ask questions, so you should monitor the upgrade and be available to respond.\nUnderstand Third-party repositories:\nThird-party software repositories and Personal Package Archives (PPAs) are disabled during the release upgrade. While software installed from these sources will not be removed, it’s the most common cause of upgrade issues. Be prepared to re-enable them or find updated versions after the upgrade.\nBackup all your data:\nAlthough upgrades are normally safe, there is always a chance that something could go wrong. It is extremely important that the data is safely copied to a backup location to allow restoration if any problems occur.\nUpgrade the system\n¶\nWe recommend upgrading the system using the\ndo-release-upgrade\ncommand on Server edition and cloud images. This command can handle system configuration changes that are sometimes needed between releases.\nTo start the process, run this command:\nsudo\ndo\n-release-upgrade\nNote\nUpgrading to a development release of Ubuntu is available using the\n-d\nflag. However, using the development release (or the\n-d\nflag) is\nnot recommended\nfor production environments.\nUpgrades from one LTS release to the next one are only available after the first point release. For example, Ubuntu 18.04 LTS will only upgrade to Ubuntu 20.04 LTS after the 20.04.1 point release. If users wish to update before the point release (e.g., on a subset of machines to evaluate the LTS upgrade) users can force the upgrade via the\n-d\nflag.\nPre-upgrade summary\n¶\nBefore making any changes the command\ndo-release-upgrade\nwill first do some checks to verify the system is ready to upgrade, and provide a summary of the upgrade before proceeding. If you accept the changes, the process will begin to update the system’s packages:\nDo you want to start the upgrade?  \n\n\n5 installed packages are no longer supported by Canonical. You can  \nstill get support from the community.  \n\n4 packages are going to be removed. 117 new packages are going to be  \ninstalled. 424 packages are going to be upgraded.  \n\nYou have to download a total of 262 M. This download will take about  \n33 minutes with a 1Mbit DSL connection and about 10 hours with a 56k  \nmodem.  \n\nFetching and installing the upgrade can take several hours. Once the  \ndownload has finished, the process cannot be canceled.  \n\nContinue [yN]  Details [d]\nConfiguration changes\n¶\nDuring the upgrade process you may be presented with a message to make decisions about package updates. These prompts occur when there are existing configuration files (e.g. edited by the user) and the new package configuration file are different. Below is an example prompt:\nConfiguration file '/etc/ssh/ssh_config'\n ==> Modified (by you or by a script) since installation.\n ==> Package distributor has shipped an updated version.\n   What would you like to do about it ?  Your options are:\n    Y or I  : install the package maintainer's version\n    N or O  : keep your currently-installed version\n      D     : show the differences between the versions\n      Z     : start a shell to examine the situation\n The default action is to keep your current version.\n*** ssh_config (Y/I/N/O/D/Z) [default=N] ?\nYou should look at the differences between the files and decide what to do. The default response is to keep the current version of the file. There are situations where accepting the new version, like with\n/boot/grub/menu.lst\n, is required for the system to boot correctly with the new kernel.\nRemoving Obsolete Packages\n¶\nAfter all packages are updated, you can choose to remove any obsolete packages that are no longer needed:\nRemove obsolete packages?  \n\n\n30 packages are going to be removed.  \n\nContinue [yN]  Details [d]\nReboot\n¶\nFinally, when the upgrade is complete you are prompted to reboot the system. The system is not considered upgraded until this reboot occurs:\nSystem upgrade is complete.\n\nRestart required  \n\nTo finish the upgrade, a restart is required.  \nIf you select 'y' the system will be restarted.  \n\nContinue [yN]\nFurther reading\n¶\nFor a complete list of releases and current support status, see the\nList of releases\npage.", "meta": {"site": "documentation.ubuntu.com", "crawl_ts": "2025-11-27T10:38:31Z", "original_len_words": 1112}}
{"id": "fa858a5095", "source_url": "https://documentation.ubuntu.com/server/how-to/storage/", "title": "Storage - Ubuntu Server documentation", "text": "Storage - Ubuntu Server documentation\nContents\nMenu\nExpand\nLight mode\nDark mode\nAuto light/dark, in light mode\nAuto light/dark, in dark mode\nSkip to content\nBack to top\nView this page\nStorage\n¶\nThe Ubuntu Server installer can set up and install to\nLogical Volume Management (LVM)\npartitions.\nUbuntu Server can be configured as both an\niSCSI initiator and an iSCSI target.\nSee also\n¶\nExplanation:\nAbout Logical Volume Management (LVM)", "meta": {"site": "documentation.ubuntu.com", "crawl_ts": "2025-11-27T10:38:31Z", "original_len_words": 71}}
{"id": "4138b57cb2", "source_url": "https://documentation.ubuntu.com/server/how-to/storage/iscsi-initiator-or-client/", "title": "iSCSI initiator (or client) - Ubuntu Server documentation", "text": "iSCSI initiator (or client) - Ubuntu Server documentation\nContents\nMenu\nExpand\nLight mode\nDark mode\nAuto light/dark, in light mode\nAuto light/dark, in dark mode\nSkip to content\nBack to top\nView this page\niSCSI initiator (or client)\n¶\nWikipedia\niSCSI Definition\n:\niSCSI an acronym for\nInternet Small Computer Systems Interface\n, an\nInternet Protocol\n(IP)-based storage networking standard for linking data storage facilities. It provides\nblock-level access\nto\nstorage devices\nby carrying\nSCSI\ncommands over a\nTCP/IP\nnetwork.\niSCSI is used to facilitate data transfers over\nintranets\nand to manage storage over long distances. It can be used to transmit data over\nlocal area networks\n(LANs),\nwide area networks\n(WANs), or the\nInternet\nand can enable location-independent data storage and retrieval.\nThe\nprotocol\nallows clients (called\ninitiators\n) to send SCSI commands (\nCDBs\n) to storage devices (\ntargets\n) on remote servers.  It is a\nstorage area network\n(SAN) protocol, allowing organizations to consolidate storage into\nstorage arrays\nwhile providing clients (such as database and web servers) with the illusion of locally attached SCSI disks.\nIt mainly competes with\nFibre Channel\n, but unlike traditional\nFibre Channel\n, which usually requires dedicated cabling, iSCSI can be run over long distances using existing network infrastructure.\nUbuntu Server can be configured as both:\niSCSI initiator\nand\niSCSI target\n. This guide provides commands and configuration options to setup an\niSCSI initiator\n(or Client).\nNote\nIt is assumed that\nyou already have an iSCSI target on your local network\nand have the appropriate rights to connect to it. The instructions for setting up a target vary greatly between hardware providers, so consult your vendor documentation to configure your specific iSCSI target.\nNetwork Interfaces Configuration\n¶\nBefore start configuring iSCSI, make sure to have the network interfaces correctly set and configured in order to have open-iscsi package to behave appropriately, specially during boot time. In Ubuntu 20.04 LTS, the default network configuration tool is\nnetplan.io\n.\nFor all the iSCSI examples below please consider the following netplan configuration for my iSCSI initiator:\n/etc/cloud/cloud.cfg.d/99-disable-network-config.cfg\n{\nconfig\n:\ndisabled\n}\n/etc/netplan/50-cloud-init.yaml\nnetwork\n:\nethernets\n:\nenp5s0\n:\nmatch\n:\nmacaddress\n:\n00\n:\n16\n:\n3\ne\n:\naf\n:\nc4\n:\nd6\nset\n-\nname\n:\neth0\ndhcp4\n:\ntrue\ndhcp\n-\nidentifier\n:\nmac\nenp6s0\n:\nmatch\n:\nmacaddress\n:\n00\n:\n16\n:\n3\ne\n:\n50\n:\n11\n:\n9\nc\nset\n-\nname\n:\niscsi01\ndhcp4\n:\ntrue\ndhcp\n-\nidentifier\n:\nmac\ndhcp4\n-\noverrides\n:\nroute\n-\nmetric\n:\n300\nenp7s0\n:\nmatch\n:\nmacaddress\n:\n00\n:\n16\n:\n3\ne\n:\nb3\n:\ncc\n:\n50\nset\n-\nname\n:\niscsi02\ndhcp4\n:\ntrue\ndhcp\n-\nidentifier\n:\nmac\ndhcp4\n-\noverrides\n:\nroute\n-\nmetric\n:\n300\nversion\n:\n2\nrenderer\n:\nnetworkd\nWith this configuration, the interfaces names change by matching their mac addresses. This makes it easier to manage them in a server containing multiple interfaces.\nFrom this point and beyond, 2 interfaces are going to be mentioned:\niscsi01\nand\niscsi02\n. This helps to demonstrate how to configure iSCSI in a multipath environment as well (check the Device Mapper Multipath session in this same Server Guide).\nIf you have only a single interface for the iSCSI network, make sure to follow the same instructions, but only consider the\niscsi01\ninterface command line examples.\niSCSI Initiator Install\n¶\nTo configure Ubuntu Server as an iSCSI initiator install the open-iscsi package. In a terminal enter:\n$ sudo apt install open-iscsi\nOnce the package is installed you will find the following files:\n/etc/iscsi/iscsid.conf\n/etc/iscsi/initiatorname.iscsi\niSCSI Initiator Configuration\n¶\nConfigure the main configuration file like the example bellow:\n/etc/iscsi/iscsid.conf\n### startup settings\n## will be controlled by systemd, leave as is\niscsid\n.\nstartup\n=\n/\nusr\n/\nsbin\n/\niscsidnode\n.\nstartup\n=\nmanual\n### chap settings\n# node.session.auth.authmethod = CHAP\n## authentication of initiator by target (session)\n# node.session.auth.username = username\n# node.session.auth.password = password\n# discovery.sendtargets.auth.authmethod = CHAP\n## authentication of initiator by target (discovery)\n# discovery.sendtargets.auth.username = username\n# discovery.sendtargets.auth.password = password\n### timeouts\n## control how much time iscsi takes to propagate an error to the\n## upper layer. if using multipath, having 0 here is desirable\n## so multipath can handle path errors as quickly as possible\n## (and decide to queue or not if missing all paths)\nnode\n.\nsession\n.\ntimeo\n.\nreplacement_timeout\n=\n0\nnode\n.\nconn\n[\n0\n]\n.\ntimeo\n.\nlogin_timeout\n=\n15\nnode\n.\nconn\n[\n0\n]\n.\ntimeo\n.\nlogout_timeout\n=\n15\n## interval for a NOP-Out request (a ping to the target)\nnode\n.\nconn\n[\n0\n]\n.\ntimeo\n.\nnoop_out_interval\n=\n5\n## and how much time to wait before declaring a timeout\nnode\n.\nconn\n[\n0\n]\n.\ntimeo\n.\nnoop_out_timeout\n=\n5\n## default timeouts for error recovery logics (lu & tgt resets)\nnode\n.\nsession\n.\nerr_timeo\n.\nabort_timeout\n=\n15\nnode\n.\nsession\n.\nerr_timeo\n.\nlu_reset_timeout\n=\n30\nnode\n.\nsession\n.\nerr_timeo\n.\ntgt_reset_timeout\n=\n30\n### retry\nnode\n.\nsession\n.\ninitial_login_retry_max\n=\n8\n### session and device queue depth\nnode\n.\nsession\n.\ncmds_max\n=\n128\nnode\n.\nsession\n.\nqueue_depth\n=\n32\n### performance\nnode\n.\nsession\n.\nxmit_thread_priority\n=\n-\n20\nand re-start the iSCSI daemon:\n$ systemctl restart iscsid.service\nThis will set basic things up for the rest of configuration.\nThe other file mentioned:\n/etc/iscsi/initiatorname.iscsi\nInitiatorName\n=\niqn\n.2004\n-\n10.\ncom\n.\nubuntu\n:\n01\n:\n60\nf3517884c3\ncontains this node’s initiator name and is generated during open-iscsi package installation. If you modify this setting, make sure that you don’t have duplicates in the same iSCSI SAN (Storage Area Network).\niSCSI Network Configuration\n¶\nBefore configuring the Logical Units that are going to be accessed by the initiator, it is important to inform the iSCSI service what are the interfaces acting as paths.\nA straightforward way to do that is by:\nconfiguring the following environment variables\n$ iscsi01_ip=$(ip -4 -o addr show iscsi01 | sed -r 's:.* (([0-9]{1,3}\\.){3}[0-9]{1,3})/.*:\\1:')\n$ iscsi02_ip=$(ip -4 -o addr show iscsi02 | sed -r 's:.* (([0-9]{1,3}\\.){3}[0-9]{1,3})/.*:\\1:')\n\n$ iscsi01_mac=$(ip -o link show iscsi01 | sed -r 's:.*\\s+link/ether (([0-f]{2}(\\:|)){6}).*:\\1:g')\n$ iscsi02_mac=$(ip -o link show iscsi02 | sed -r 's:.*\\s+link/ether (([0-f]{2}(\\:|)){6}).*:\\1:g')\nconfiguring\niscsi01\ninterface\n$ sudo iscsiadm -m iface -I iscsi01 --op=new\nNew interface iscsi01 added\n$ sudo iscsiadm -m iface -I iscsi01 --op=update -n iface.hwaddress -v $iscsi01_mac\niscsi01 updated.\n$ sudo iscsiadm -m iface -I iscsi01 --op=update -n iface.ipaddress -v $iscsi01_ip\niscsi01 updated.\nconfiguring\niscsi02\ninterface\n$ sudo iscsiadm -m iface -I iscsi02 --op=new\nNew interface iscsi02 added\n$ sudo iscsiadm -m iface -I iscsi02 --op=update -n iface.hwaddress -v $iscsi02_mac\niscsi02 updated.\n$ sudo iscsiadm -m iface -I iscsi02 --op=update -n iface.ipaddress -v $iscsi02_ip\niscsi02 updated.\ndiscovering the\ntargets\n$ sudo iscsiadm -m discovery -I iscsi01 --op=new --op=del --type sendtargets --portal storage.iscsi01\n10.250.94.99:3260,1 iqn.2003-01.org.linux-iscsi.storage.x8664:sn.2c084c8320ca\n\n$ sudo iscsiadm -m discovery -I iscsi02 --op=new --op=del --type sendtargets --portal storage.iscsi02\n10.250.93.99:3260,1 iqn.2003-01.org.linux-iscsi.storage.x8664:sn.2c084c8320ca\nconfiguring\nautomatic login\n$ sudo iscsiadm -m node --op=update -n node.conn[0].startup -v automatic\n$ sudo iscsiadm -m node --op=update -n node.startup -v automatic\nmake sure needed\nservices\nare enabled during OS initialization:\n$ systemctl enable open-iscsi\nSynchronizing state of open-iscsi.service with SysV service script with /lib/systemd/systemd-sysv-install.\nExecuting: /lib/systemd/systemd-sysv-install enable open-iscsi\nCreated symlink /etc/systemd/system/iscsi.service → /lib/systemd/system/open-iscsi.service.\nCreated symlink /etc/systemd/system/sysinit.target.wants/open-iscsi.service → /lib/systemd/system/open-iscsi.service.\n\n$ systemctl enable iscsid\nSynchronizing state of iscsid.service with SysV service script with /lib/systemd/systemd-sysv-install.\nExecuting: /lib/systemd/systemd-sysv-install enable iscsid\nCreated symlink /etc/systemd/system/sysinit.target.wants/iscsid.service → /lib/systemd/system/iscsid.service.\nrestarting\niscsid\nservice\n$ systemctl restart iscsid.service\nand, finally,\nlogin in\ndiscovered logical units\n$ sudo iscsiadm -m node --loginall=automatic\nLogging in to [iface: iscsi02, target: iqn.2003-01.org.linux-iscsi.storage.x8664:sn.2c084c8320ca, portal: 10.250.93.99,3260] (multiple)\nLogging in to [iface: iscsi01, target: iqn.2003-01.org.linux-iscsi.storage.x8664:sn.2c084c8320ca, portal: 10.250.94.99,3260] (multiple)\nLogin to [iface: iscsi02, target: iqn.2003-01.org.linux-iscsi.storage.x8664:sn.2c084c8320ca, portal: 10.250.93.99,3260] successful.\nLogin to [iface: iscsi01, target: iqn.2003-01.org.linux-iscsi.storage.x8664:sn.2c084c8320ca, portal: 10.250.94.99,3260] successful.\nAccessing the Logical Units (or LUNs)\n¶\nCheck\ndmesg\nto make sure that the new disks have been detected:\ndmesg\n[\n166.840694\n]\nscsi\n7\n:\n0\n:\n0\n:\n4\n:\nDirect\n-\nAccess\nLIO\n-\nORG\nTCMU\ndevice\n>\n0002\nPQ\n:\n0\nANSI\n:\n5\n[\n166.840892\n]\nscsi\n8\n:\n0\n:\n0\n:\n4\n:\nDirect\n-\nAccess\nLIO\n-\nORG\nTCMU\ndevice\n>\n0002\nPQ\n:\n0\nANSI\n:\n5\n[\n166.841741\n]\nsd\n7\n:\n0\n:\n0\n:\n4\n:\nAttached\nscsi\ngeneric\nsg2\ntype\n0\n[\n166.841808\n]\nsd\n8\n:\n0\n:\n0\n:\n4\n:\nAttached\nscsi\ngeneric\nsg3\ntype\n0\n[\n166.842278\n]\nscsi\n7\n:\n0\n:\n0\n:\n3\n:\nDirect\n-\nAccess\nLIO\n-\nORG\nTCMU\ndevice\n>\n0002\nPQ\n:\n0\nANSI\n:\n5\n[\n166.842571\n]\nscsi\n8\n:\n0\n:\n0\n:\n3\n:\nDirect\n-\nAccess\nLIO\n-\nORG\nTCMU\ndevice\n>\n0002\nPQ\n:\n0\nANSI\n:\n5\n[\n166.843482\n]\nsd\n8\n:\n0\n:\n0\n:\n3\n:\nAttached\nscsi\ngeneric\nsg4\ntype\n0\n[\n166.843681\n]\nsd\n7\n:\n0\n:\n0\n:\n3\n:\nAttached\nscsi\ngeneric\nsg5\ntype\n0\n[\n166.843706\n]\nsd\n8\n:\n0\n:\n0\n:\n4\n:\n[\nsdd\n]\n2097152\n512\n-\nbyte\nlogical\nblocks\n:\n>\n(\n1.07\nGB\n/\n1.00\nGiB\n)\n[\n166.843884\n]\nscsi\n8\n:\n0\n:\n0\n:\n2\n:\nDirect\n-\nAccess\nLIO\n-\nORG\nTCMU\ndevice\n>\n0002\nPQ\n:\n0\nANSI\n:\n5\n[\n166.843971\n]\nsd\n8\n:\n0\n:\n0\n:\n4\n:\n[\nsdd\n]\nWrite\nProtect\nis\noff\n[\n166.843972\n]\nsd\n8\n:\n0\n:\n0\n:\n4\n:\n[\nsdd\n]\nMode\nSense\n:\n2\nf\n00\n00\n00\n[\n166.844127\n]\nscsi\n7\n:\n0\n:\n0\n:\n2\n:\nDirect\n-\nAccess\nLIO\n-\nORG\nTCMU\ndevice\n>\n0002\nPQ\n:\n0\nANSI\n:\n5\n[\n166.844232\n]\nsd\n7\n:\n0\n:\n0\n:\n4\n:\n[\nsdc\n]\n2097152\n512\n-\nbyte\nlogical\nblocks\n:\n>\n(\n1.07\nGB\n/\n1.00\nGiB\n)\n[\n166.844421\n]\nsd\n8\n:\n0\n:\n0\n:\n4\n:\n[\nsdd\n]\nWrite\ncache\n:\nenabled\n,\nread\ncache\n:\n>\nenabled\n,\ndoesn\n't support DPO or FUA\n[\n166.844566\n]\nsd\n7\n:\n0\n:\n0\n:\n4\n:\n[\nsdc\n]\nWrite\nProtect\nis\noff\n[\n166.844568\n]\nsd\n7\n:\n0\n:\n0\n:\n4\n:\n[\nsdc\n]\nMode\nSense\n:\n2\nf\n00\n00\n00\n[\n166.844846\n]\nsd\n8\n:\n0\n:\n0\n:\n2\n:\nAttached\nscsi\ngeneric\nsg6\ntype\n0\n[\n166.845147\n]\nsd\n7\n:\n0\n:\n0\n:\n4\n:\n[\nsdc\n]\nWrite\ncache\n:\nenabled\n,\nread\ncache\n:\n>\nenabled\n,\ndoesn\n't support DPO or FUA\n[\n166.845188\n]\nsd\n8\n:\n0\n:\n0\n:\n4\n:\n[\nsdd\n]\nOptimal\ntransfer\nsize\n65536\nbytes\n[\n166.845527\n]\nsd\n7\n:\n0\n:\n0\n:\n2\n:\nAttached\nscsi\ngeneric\nsg7\ntype\n0\n[\n166.845678\n]\nsd\n8\n:\n0\n:\n0\n:\n3\n:\n[\nsde\n]\n2097152\n512\n-\nbyte\nlogical\nblocks\n:\n>\n(\n1.07\nGB\n/\n1.00\nGiB\n)\n[\n166.845785\n]\nscsi\n8\n:\n0\n:\n0\n:\n1\n:\nDirect\n-\nAccess\nLIO\n-\nORG\nTCMU\ndevice\n>\n0002\nPQ\n:\n0\nANSI\n:\n5\n[\n166.845799\n]\nsd\n7\n:\n0\n:\n0\n:\n4\n:\n[\nsdc\n]\nOptimal\ntransfer\nsize\n65536\nbytes\n[\n166.845931\n]\nsd\n8\n:\n0\n:\n0\n:\n3\n:\n[\nsde\n]\nWrite\nProtect\nis\noff\n[\n166.845933\n]\nsd\n8\n:\n0\n:\n0\n:\n3\n:\n[\nsde\n]\nMode\nSense\n:\n2\nf\n00\n00\n00\n[\n166.846424\n]\nscsi\n7\n:\n0\n:\n0\n:\n1\n:\nDirect\n-\nAccess\nLIO\n-\nORG\nTCMU\ndevice\n>\n0002\nPQ\n:\n0\nANSI\n:\n5\n[\n166.846552\n]\nsd\n8\n:\n0\n:\n0\n:\n3\n:\n[\nsde\n]\nWrite\ncache\n:\nenabled\n,\nread\ncache\n:\n>\nenabled\n,\ndoesn\n't support DPO or FUA\n[\n166.846708\n]\nsd\n7\n:\n0\n:\n0\n:\n3\n:\n[\nsdf\n]\n2097152\n512\n-\nbyte\nlogical\nblocks\n:\n>\n(\n1.07\nGB\n/\n1.00\nGiB\n)\n[\n166.847024\n]\nsd\n8\n:\n0\n:\n0\n:\n1\n:\nAttached\nscsi\ngeneric\nsg8\ntype\n0\n[\n166.847029\n]\nsd\n7\n:\n0\n:\n0\n:\n3\n:\n[\nsdf\n]\nWrite\nProtect\nis\noff\n[\n166.847031\n]\nsd\n7\n:\n0\n:\n0\n:\n3\n:\n[\nsdf\n]\nMode\nSense\n:\n2\nf\n00\n00\n00\n[\n166.847043\n]\nsd\n8\n:\n0\n:\n0\n:\n3\n:\n[\nsde\n]\nOptimal\ntransfer\nsize\n65536\nbytes\n[\n166.847133\n]\nsd\n8\n:\n0\n:\n0\n:\n2\n:\n[\nsdg\n]\n2097152\n512\n-\nbyte\nlogical\nblocks\n:\n>\n(\n1.07\nGB\n/\n1.00\nGiB\n)\n[\n166.849212\n]\nsd\n8\n:\n0\n:\n0\n:\n2\n:\n[\nsdg\n]\nWrite\nProtect\nis\noff\n[\n166.849214\n]\nsd\n8\n:\n0\n:\n0\n:\n2\n:\n[\nsdg\n]\nMode\nSense\n:\n2\nf\n00\n00\n00\n[\n166.849711\n]\nsd\n7\n:\n0\n:\n0\n:\n3\n:\n[\nsdf\n]\nWrite\ncache\n:\nenabled\n,\nread\ncache\n:\n>\nenabled\n,\ndoesn\n't support DPO or FUA\n[\n166.849718\n]\nsd\n7\n:\n0\n:\n0\n:\n1\n:\nAttached\nscsi\ngeneric\nsg9\ntype\n0\n[\n166.849721\n]\nsd\n7\n:\n0\n:\n0\n:\n2\n:\n[\nsdh\n]\n2097152\n512\n-\nbyte\nlogical\nblocks\n:\n>\n(\n1.07\nGB\n/\n1.00\nGiB\n)\n[\n166.853296\n]\nsd\n8\n:\n0\n:\n0\n:\n2\n:\n[\nsdg\n]\nWrite\ncache\n:\nenabled\n,\nread\ncache\n:\n>\nenabled\n,\ndoesn\n't support DPO or FUA\n[\n166.853721\n]\nsd\n8\n:\n0\n:\n0\n:\n2\n:\n[\nsdg\n]\nOptimal\ntransfer\nsize\n65536\nbytes\n[\n166.853810\n]\nsd\n7\n:\n0\n:\n0\n:\n2\n:\n[\nsdh\n]\nWrite\nProtect\nis\noff\n[\n166.853812\n]\nsd\n7\n:\n0\n:\n0\n:\n2\n:\n[\nsdh\n]\nMode\nSense\n:\n2\nf\n00\n00\n00\n[\n166.854026\n]\nsd\n7\n:\n0\n:\n0\n:\n3\n:\n[\nsdf\n]\nOptimal\ntransfer\nsize\n65536\nbytes\n[\n166.854431\n]\nsd\n7\n:\n0\n:\n0\n:\n2\n:\n[\nsdh\n]\nWrite\ncache\n:\nenabled\n,\nread\ncache\n:\n>\nenabled\n,\ndoesn\n't support DPO or FUA\n[\n166.854625\n]\nsd\n8\n:\n0\n:\n0\n:\n1\n:\n[\nsdi\n]\n2097152\n512\n-\nbyte\nlogical\nblocks\n:\n>\n(\n1.07\nGB\n/\n1.00\nGiB\n)\n[\n166.854898\n]\nsd\n8\n:\n0\n:\n0\n:\n1\n:\n[\nsdi\n]\nWrite\nProtect\nis\noff\n[\n166.854900\n]\nsd\n8\n:\n0\n:\n0\n:\n1\n:\n[\nsdi\n]\nMode\nSense\n:\n2\nf\n00\n00\n00\n[\n166.855022\n]\nsd\n7\n:\n0\n:\n0\n:\n2\n:\n[\nsdh\n]\nOptimal\ntransfer\nsize\n65536\nbytes\n[\n166.855465\n]\nsd\n8\n:\n0\n:\n0\n:\n1\n:\n[\nsdi\n]\nWrite\ncache\n:\nenabled\n,\nread\ncache\n:\n>\nenabled\n,\ndoesn\n't support DPO or FUA\n[\n166.855578\n]\nsd\n7\n:\n0\n:\n0\n:\n1\n:\n[\nsdj\n]\n2097152\n512\n-\nbyte\nlogical\nblocks\n:\n>\n(\n1.07\nGB\n/\n1.00\nGiB\n)\n[\n166.855845\n]\nsd\n7\n:\n0\n:\n0\n:\n1\n:\n[\nsdj\n]\nWrite\nProtect\nis\noff\n[\n166.855847\n]\nsd\n7\n:\n0\n:\n0\n:\n1\n:\n[\nsdj\n]\nMode\nSense\n:\n2\nf\n00\n00\n00\n[\n166.855978\n]\nsd\n8\n:\n0\n:\n0\n:\n1\n:\n[\nsdi\n]\nOptimal\ntransfer\nsize\n65536\nbytes\n[\n166.856305\n]\nsd\n7\n:\n0\n:\n0\n:\n1\n:\n[\nsdj\n]\nWrite\ncache\n:\nenabled\n,\nread\ncache\n:\n>\nenabled\n,\ndoesn\n't support DPO or FUA\n[\n166.856701\n]\nsd\n7\n:\n0\n:\n0\n:\n1\n:\n[\nsdj\n]\nOptimal\ntransfer\nsize\n65536\nbytes\n[\n166.859624\n]\nsd\n8\n:\n0\n:\n0\n:\n4\n:\n[\nsdd\n]\nAttached\nSCSI\ndisk\n[\n166.861304\n]\nsd\n7\n:\n0\n:\n0\n:\n4\n:\n[\nsdc\n]\nAttached\nSCSI\ndisk\n[\n166.864409\n]\nsd\n8\n:\n0\n:\n0\n:\n3\n:\n[\nsde\n]\nAttached\nSCSI\ndisk\n[\n166.864833\n]\nsd\n7\n:\n0\n:\n0\n:\n3\n:\n[\nsdf\n]\nAttached\nSCSI\ndisk\n[\n166.867906\n]\nsd\n8\n:\n0\n:\n0\n:\n2\n:\n[\nsdg\n]\nAttached\nSCSI\ndisk\n[\n166.868446\n]\nsd\n8\n:\n0\n:\n0\n:\n1\n:\n[\nsdi\n]\nAttached\nSCSI\ndisk\n[\n166.871588\n]\nsd\n7\n:\n0\n:\n0\n:\n1\n:\n[\nsdj\n]\nAttached\nSCSI\ndisk\n[\n166.871773\n]\nsd\n7\n:\n0\n:\n0\n:\n2\n:\n[\nsdh\n]\nAttached\nSCSI\ndisk\nIn the output above you will find\n8 x SCSI disks\nrecognized. The storage server is mapping\n4 x LUNs\nto this node, AND the node has\n2  x PATHs\nto each LUN. The OS recognizes each path to each device as 1 SCSI device.\nYou will find different output depending on the storage server your node is mapping the LUNs from, and the amount of LUNs being mapped as well.\nAlthough not the objective of this session, let’s find the 4 mapped LUNs using multipath-tools.\nYou will find further details about multipath in “Device Mapper Multipathing” session of this same guide.\n$ apt-get install multipath-tools\n$ sudo multipath -r\n$ sudo multipath -ll\nmpathd (360014051a042fb7c41c4249af9f2cfbc) dm-3 LIO-ORG,TCMU device\nsize=1.0G features='0' hwhandler='0' wp=rw\n|-+- policy='service-time 0' prio=1 status=active\n| `- 7:0:0:4 sde 8:64  active ready running\n`-+- policy='service-time 0' prio=1 status=enabled\n  `- 8:0:0:4 sdc 8:32  active ready running\nmpathc (360014050d6871110232471d8bcd155a3) dm-2 LIO-ORG,TCMU device\nsize=1.0G features='0' hwhandler='0' wp=rw\n|-+- policy='service-time 0' prio=1 status=active\n| `- 7:0:0:3 sdf 8:80  active ready running\n`-+- policy='service-time 0' prio=1 status=enabled\n  `- 8:0:0:3 sdd 8:48  active ready running\nmpathb (360014051f65c6cb11b74541b703ce1d4) dm-1 LIO-ORG,TCMU device\nsize=1.0G features='0' hwhandler='0' wp=rw\n|-+- policy='service-time 0' prio=1 status=active\n| `- 7:0:0:2 sdh 8:112 active ready running\n`-+- policy='service-time 0' prio=1 status=enabled\n  `- 8:0:0:2 sdg 8:96  active ready running\nmpatha (36001405b816e24fcab64fb88332a3fc9) dm-0 LIO-ORG,TCMU device\nsize=1.0G features='0' hwhandler='0' wp=rw\n|-+- policy='service-time 0' prio=1 status=active\n| `- 7:0:0:1 sdj 8:144 active ready running\n`-+- policy='service-time 0' prio=1 status=enabled\n  `- 8:0:0:1 sdi 8:128 active ready running\nNow it is much easier to understand each recognized SCSI device and common paths to same LUNs in the storage server. With the output above one can easily see that:\nmpatha device\n(/dev/mapper/mpatha) is a multipath device for:\n/dev/sdj\n/dev/dsi\nmpathb device\n(/dev/mapper/mpathb) is a multipath device for:\n/dev/sdh\n/dev/dsg\nmpathc device\n(/dev/mapper/mpathc) is a multipath device for:\n/dev/sdf\n/dev/sdd\nmpathd device\n(/dev/mapper/mpathd) is a multipath device for:\n/dev/sde\n/dev/sdc\nDo not use this in production\nwithout checking appropriate multipath configuration options in the\nDevice Mapper Multipathing\nsession. The\ndefault multipath configuration\nis less than optimal for regular usage.\nFinally, to access the LUN (or remote iSCSI disk) you will:\nIf accessing through a single network interface:\naccess it through /dev/sdX where X is a letter given by the OS\nIf accessing through multiple network interfaces:\nconfigure multipath and access the device through /dev/mapper/X\nFor everything else, the created devices are block devices and all commands used with local disks should work the same way:\nCreating a partition:\n$ sudo fdisk /dev/mapper/mpatha\n\nWelcome to fdisk (util-linux 2.34).\nChanges will remain in memory only, until you decide to write them.\nBe careful before using the write command.\n\nDevice does not contain a recognized partition table.\nCreated a new DOS disklabel with disk identifier 0x92c0322a.\n\nCommand (m for help): p\nDisk /dev/mapper/mpatha: 1 GiB, 1073741824 bytes, 2097152 sectors\nUnits: sectors of 1 * 512 = 512 bytes\nSector size (logical/physical): 512 bytes / 512 bytes\nI/O size (minimum/optimal): 512 bytes / 65536 bytes\nDisklabel type: dos\nDisk identifier: 0x92c0322a\n\nCommand (m for help): n\nPartition type\n   p   primary (0 primary, 0 extended, 4 free)\n   e   extended (container for logical partitions)\nSelect (default p): p\nPartition number (1-4, default 1):\nFirst sector (2048-2097151, default 2048):\nLast sector, +/-sectors or +/-size{K,M,G,T,P} (2048-2097151, default 2097151):\n\nCreated a new partition 1 of type 'Linux' and of size 1023 MiB.\n\nCommand (m for help): w\nThe partition table has been altered.\nCreating a\nfilesystem\n:\n$ sudo mkfs.ext4 /dev/mapper/mpatha-part1\nmke2fs 1.45.5 (07-Jan-2020)\nCreating filesystem with 261888 4k blocks and 65536 inodes\nFilesystem UUID: cdb70b1e-c47c-47fd-9c4a-03db6f038988\nSuperblock backups stored on blocks:\n        32768, 98304, 163840, 229376\n\nAllocating group tables: done\nWriting inode tables: done\nCreating journal (4096 blocks): done\nWriting superblocks and filesystem accounting information: done\nMounting the block device:\n$ sudo mount /dev/mapper/mpatha-part1 /mnt\nAccessing the data:\n$ ls /mnt\nlost+found\nMake sure to read other important sessions in Ubuntu Server Guide to follow up with concepts explored in this one.\nReferences\n¶\niscsid\niscsi.conf\niscsid.conf\niscsi.service\niscsid.service\nOpen-iSCSI\nDebian Open-iSCSI", "meta": {"site": "documentation.ubuntu.com", "crawl_ts": "2025-11-27T10:38:31Z", "original_len_words": 3506}}
{"id": "6df78d4635", "source_url": "https://documentation.ubuntu.com/server/how-to/storage/manage-logical-volumes/", "title": "How to manage logical volumes - Ubuntu Server documentation", "text": "How to manage logical volumes - Ubuntu Server documentation\nContents\nMenu\nExpand\nLight mode\nDark mode\nAuto light/dark, in light mode\nAuto light/dark, in dark mode\nSkip to content\nBack to top\nView this page\nHow to manage logical volumes\n¶\nThe Ubuntu Server installer has the ability to set up and install to LVM partitions, and this is the supported way of doing so. If you would like to know more about any of the topics in this page, refer to our\nexplanation of logical volume management (LVM)\n.\nCreate the physical volume\n¶\nFirst, you need a physical volume. Typically you start with a hard disk, and create a regular partition whose type is “LVM” on it. You can create it with\ngparted\nor\nfdisk\n, and usually only want one LVM-type partition in the whole disk, since LVM will handle subdividing it into logical volumes. In\ngparted\n, you need to check the\nlvm\nflag when creating the partition, and with\nfdisk\n, tag the type with code\n8e\n.\nOnce you have your LVM partition, you need to initialize it as a physical volume. Assuming this partition is\n/dev/sda1\n:\nsudo\npvcreate\n/dev/sda1\nCreate the volume group\n¶\nAfter that, you can create a volume group; in our example, it will be named\nfoo\nand uses only one physical volume:\nsudo\nvgcreate\nfoo\n/dev/sda1\nCreate a logical volume\n¶\nNow you want to create a logical volume from some of the free space in\nfoo\n:\nsudo\nlvcreate\n--name\nbar\n--size\n5g\nfoo\nThis creates a logical volume named\nbar\nin volume group\nfoo\nusing 5 GB of space. You can find the block device for this logical volume in\n/dev/foo/bar\nor\ndev/mapper/foo-bar\n.\nYou might also want to try the\nlvs\nand\npvs\ncommands, which list the logical volumes and physical volumes respectively, and their more detailed variants;\nlvdisplay\nand\npvdisplay\n.\nResize a partition\n¶\nYou can extend a logical volume with:\nsudo\nlvextend\n--resizefs\n--size\n+5g\nfoo/bar\nThis will add 5 GB to the\nbar\nlogical volume in the\nfoo\nvolume group, and will automatically resize the underlying\nfilesystem\n(if supported). The space is allocated from free space anywhere in the\nbar\nvolume group. You can specify an absolute size instead of a relative size if you want by omitting the leading\n+\n.\nIf you have multiple physical volumes you can add the names of one (or more) of them to the end of the command to limit which ones are used to fulfill the request.\nMove a partition\n¶\nIf you only have one physical volume then you are unlikely to ever need to move, but if you add a new disk, you might want to. To move the logical volume\nbar\noff of physical volume\n/dev/sda1\n, you can run:\nsudo\npvmove\n--name\nbar\n/dev/sda1\nIf you omit the\n--name\nbar\nargument, then all logical volumes on the\n/dev/sda1\nphysical volume will be moved. If you only have one other physical volume then that is where it will be moved to. Otherwise you can add the name of one or more specific physical volumes that should be used to satisfy the request, instead of any physical volume in the volume group with free space.\nThis process can be resumed safely if interrupted by a crash or power failure, and can be done while the logical volume(s) in question are in use. You can also add\n--background\nto perform the move in the background and return immediately, or\n--interval\ns\nto have it print how much progress it has made every\ns\nseconds. If you background the move, you can check its progress with the\nlvs\ncommand.\nCreate a snapshot\n¶\nWhen you create a snapshot, you create a new logical volume to act as a clone of the original logical volume.\nThe snapshot volume does not initially use any space, but as changes are made to the original volume, the changed blocks are copied to the snapshot volume before they are changed in order to preserve them. This means that the more changes you make to the origin, the more space the snapshot needs. If the snapshot volume uses all of the space allocated to it, then the snapshot is broken and can not be used any more, leaving you with only the modified origin.\nThe\nlvs\ncommand will tell you how much space has been used in a snapshot logical volume. If it starts to get full, you might want to extend it with the\nlvextend\ncommand. To create a snapshot of the bar logical volume and name it\nlv_snapshot\n, run:\nsudo\nlvcreate\n--snapshot\n--name\nlv_snapshot\n--size\n5g\nfoo/bar\nThis will create a snapshot named\nlv_snapshot\nof the original logical volume\nbar\nand allocate 5 GB of space for it. Since the snapshot volume only stores the areas of the disk that have changed since it was created, it can be much smaller than the original volume.\nWhile you have the snapshot, you can mount it if you wish to see the original filesystem as it appeared when you made the snapshot. In the above example you would mount the\n/dev/foo/lv_snapshot\ndevice. You can modify the snapshot without affecting the original, and the original without affecting the snapshot. For example, if you take a snapshot of your root logical volume, make changes to your system, and then decide you would like to revert the system back to its previous state, you can merge the snapshot back into the original volume, which effectively reverts it to the state it was in when you made the snapshot. To do this, you can run:\nsudo\nlvconvert\n--merge\nfoo/lv_snapshot\nIf the origin volume of\nfoo/lv_snapshot\nis in use, it will inform you that the merge will take place the next time the volumes are activated. If this is the root volume, then you will need to reboot for this to happen. At the next boot, the volume will be activated and the merge will begin in the background, so your system will boot up as if you had never made the changes since the snapshot was created, and the actual data movement will take place in the background while you work.", "meta": {"site": "documentation.ubuntu.com", "crawl_ts": "2025-11-27T10:38:32Z", "original_len_words": 1039}}
{"id": "adbafa3641", "source_url": "https://documentation.ubuntu.com/server/how-to/virtualisation/", "title": "Virtualisation - Ubuntu Server documentation", "text": "Virtualisation - Ubuntu Server documentation\nContents\nMenu\nExpand\nLight mode\nDark mode\nAuto light/dark, in light mode\nAuto light/dark, in dark mode\nSkip to content\nBack to top\nView this page\nVirtualisation\n¶\nIn this section we show how to install, configure and use various options for creating virtual machines (VMs). For more information about these options, you may want to refer to our\nIntroduction to virtualization\nVirtual machines\n¶\nCreate VMs with Multipass\nCreate cloud image VMs with UVtool\nQEMU\nConfidential Computing with AMD\nVM tooling\n¶\nHow to use the libvirt library with virsh\nHow to use virt-manager and other virt* tools\nHow to enable nested virtualisation\nUbuntu in other virtual environments\n¶\nSetting up Ubuntu on Hyper-V\n(Windows 11)\nSee also\n¶\nExplanation:\nVirtualisation and containers", "meta": {"site": "documentation.ubuntu.com", "crawl_ts": "2025-11-27T10:38:32Z", "original_len_words": 129}}
{"id": "2c2cc48c2f", "source_url": "https://documentation.ubuntu.com/server/how-to/virtualisation/cloud-image-vms-with-uvtool/", "title": "Create cloud image VMs with UVtool - Ubuntu Server documentation", "text": "Create cloud image VMs with UVtool - Ubuntu Server documentation\nContents\nMenu\nExpand\nLight mode\nDark mode\nAuto light/dark, in light mode\nAuto light/dark, in dark mode\nSkip to content\nBack to top\nView this page\nCreate cloud image VMs with UVtool\n¶\nWith Ubuntu being one of the most popular operating systems on many cloud platforms, the availability of stable and secure cloud images has become very important. Since Ubuntu 12.04, the use of cloud images outside of a cloud infrastructure has been improved so that it is now possible to use those images to create a virtual machine without needing a complete installation.\nCreating virtual machines using\nuvtool\n¶\nStarting with Ubuntu 14.04 LTS, a tool called\nuvtool\nhas greatly facilitated the creation of virtual machines (VMs) using cloud images.\nuvtool\nprovides a simple mechanism for synchronizing cloud images locally and using them to create new VMs in minutes.\nInstall\nuvtool\npackages\n¶\nThe following packages and their dependencies are required in order to use\nuvtool\n:\nuvtool\nuvtool-libvirt\nTo install\nuvtool\n, run:\nsudo\napt\n-y\ninstall\nuvtool\nThis will install\nuvtool\n’s main commands,\nuvt-simplestreams-libvirt\nand\nuvt-kvm\n.\nGet the Ubuntu cloud image with\nuvt-simplestreams-libvirt\n¶\nThis is one of the major simplifications that\nuvtool\nprovides. It knows where to find the cloud images so you only need one command to get a new cloud image. For instance, if you want to synchronize all cloud images for the amd64 architecture, the\nuvtool\ncommand would be:\nuvt-simplestreams-libvirt\n--verbose\nsync\narch\n=\namd64\nAfter all the images have been downloaded from the Internet, you will have a complete set of locally-stored cloud images. To see what has been downloaded, use the following command:\nuvt-simplestreams-libvirt\nquery\nWhich will provide you with a list like this:\nrelease=bionic arch=amd64 label=daily (20191107)\nrelease=focal arch=amd64 label=daily (20191029)\n...\nIn the case where you want to synchronize only one specific cloud image, you need to use the\nrelease=\nand\narch=\nfilters to identify which image needs to be synchronized.\nuvt-simplestreams-libvirt\nsync\nrelease\n=\nDISTRO-SHORT-CODENAME\narch\n=\namd64\nFurthermore, you can provide an alternative URL to fetch images from. A common case is the daily image, which helps you get the very latest images, or if you need access to the not-yet-released development release of Ubuntu. As an example:\nuvt-simplestreams-libvirt\nsync\n--source\nhttp://cloud-images.ubuntu.com/daily\n[\n...\nfurther\noptions\n]\nCreate a valid SSH key\n¶\nTo connect to the virtual machine once it has been created, you must first have a valid SSH key available for the Ubuntu user. If your environment does not have an SSH key, you can create one using the\nssh-keygen\ncommand, which will produce similar output to this:\nGenerating public/private rsa key pair.\nEnter file in which to save the key (/home/ubuntu/.ssh/id_rsa): \nEnter passphrase (empty for no passphrase): \nEnter same passphrase again: \nYour identification has been saved in /home/ubuntu/.ssh/id_rsa.\nYour public key has been saved in /home/ubuntu/.ssh/id_rsa.pub.\nThe key fingerprint is:\n4d:ba:5d:57:c9:49:ef:b5:ab:71:14:56:6e:2b:ad:9b ubuntu@DISTRO-SHORT-CODENAMES\nThe key's randomart image is:\n+--[ RSA 2048]----+\n|               ..|\n|              o.=|\n|          .    **|\n|         +    o+=|\n|        S . ...=.|\n|         o . .+ .|\n|        . .  o o |\n|              *  |\n|             E   |\n+-----------------+\nCreate the VM using\nuvt-kvm\n¶\nTo create a new virtual machine using\nuvtool\n, run the following in a terminal:\nuvt-kvm\ncreate\nfirsttest\nThis will create a VM named ‘firsttest’ using the current locally-available LTS cloud image. If you want to specify a release to be used to create the VM, you need to use the\nrelease=\nfilter, and the short codename of the release, e.g. “jammy”:\nuvt-kvm\ncreate\nsecondtest\nrelease\n=\nDISTRO-SHORT-CODENAME\nThe\nuvt-kvm\nwait\ncommand can be used to wait until the creation of the VM has completed:\nuvt-kvm\nwait\nsecondttest\nConnect to the running VM\n¶\nOnce the virtual machine creation is completed, you can connect to it using SSH:\nuvt-kvm\nssh\nsecondtest\nYou can also connect to your VM using a regular SSH session using the IP address of the VM. The address can be queried using the following command:\n$\nuvt-kvm\nip\nsecondtest\n192\n.168.122.199\n$\nssh\n-i\n~/.ssh/id_rsa\nubuntu@192.168.122.199\n[\n...\n]\nTo\nrun\na\ncommand\nas\nadministrator\n(\nuser\n\"root\"\n)\n,\nuse\n\"sudo <command>\"\n.\nSee\n\"man sudo_root\"\nfor\ndetails.\n\nubuntu@secondtest:~$\nGet the list of running VMs\n¶\nYou can get the list of VMs running on your system with the\nuvt-kvm\nlist\ncommand.\nDestroy your VM\n¶\nOnce you are finished with your VM, you can destroy it with:\nuvt-kvm\ndestroy\nsecondtest\nNote\nUnlike libvirt’s\ndestroy\nor\nundefine\nactions, this will (by default) also remove the associated virtual storage files.\nMore\nuvt-kvm\noptions\n¶\nThe following options can be used to change some of the characteristics of the VM that you are creating:\n--memory\n: Amount of RAM in megabytes. Default: 512.\n--disk\n: Size of the OS disk in gigabytes. Default: 8.\n--cpu\n: Number of CPU cores. Default: 1.\nSome other parameters will have an impact on the cloud-init configuration:\n--password\n<password>\n: Allows logging into the VM using the Ubuntu account and this provided password.\n--run-script-once\n<script_file>\n: Run\nscript_file\nas root on the VM the first time it is booted, but never again.\n--packages\n<package_list>\n: Install the comma-separated packages specified in\npackage_list\non first boot.\nA complete description of all available modifiers is available in the\nuvt-kvm(1)\nmanpages.\nResources\n¶\nIf you are interested in learning more, have questions or suggestions, please contact the Ubuntu Server Team at:\nIRC:\n#ubuntu-server\non Libera\nMailing list:\nubuntu-server at lists.ubuntu.com", "meta": {"site": "documentation.ubuntu.com", "crawl_ts": "2025-11-27T10:38:32Z", "original_len_words": 924}}
